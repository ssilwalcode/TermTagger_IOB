sent,tags
"This article proposes ESA , a new unsupervised approach to word segmentation .",O O O B O O O B O O B I O
"ESA is an iterative process consisting of 3 phases : Evaluation , Selection , and Adjustment .",B O O O O O O O O O B O B O O B O
"In Evaluation , both certainty and uncertainty of character sequence co - occurrence in corpora are considered as the statistical evidence supporting goodness measurement .",O B O O O O O O B I O O O O B O O O O O O O B I O
"Additionally , the statistical data of character sequences with various lengths become comparable with each other by using a simple process called Balancing .",O O O O O O B I O O O O O O O O O O O O O O B O
"In Selection , a local maximum strategy is adopted without thresholds , and the strategy can be implemented with dynamic programming .",O B O O B I O O O O B O O O O O O O O B I O
"In Adjustment , a part of the statistical data is updated to improve successive results .",O B O O O O O O O O O O O O O O
"In our experiment , ESA was evaluated on the SIGHAN Bakeoff-2 data set .",O O O O B O O O O B I I I O
The results suggest that ESA is effective on Chinese corpora .,O O O O B O O O O B O
It is noteworthy that the F - measures of the results are basically monotone increasing and can rapidly converge to relatively high values .,O O O O O B I I O O O O O B I O O O B O O O O O
"Furthermore , the empirical formulae based on the results can be used to predict the parameter in ESA to avoid parameter estimation that is usually time - consuming .",O O O O O O O O O O O O O O O B O B O O B I O O O O O O O
We propose a framework for using multiple sources of linguistic information in the task of identifying multiword expressions in natural language texts .,O O O B O O O O O B I O O O O O B I O B I I O
We define various linguistically motivated classification features and introduce novel ways for computing them .,O O O B O B I O O O O O O O O
"We then manually define interrelationships among the features , and express them in a Bayesian network .",O O O O B O O B O O O O O O B I O
The result is a powerful classifier that can identify multiword expressions of various types and multiple syntactic constructions in text corpora .,O O O O O B O O O B I O O O O O B I O B B O
Our methodology is unsupervised and language - independent ; it requires relatively few language resources and is thus suitable for a large number of languages .,O B O B O B I I O O O O O B I O O O O O O O O O B O
"We report results on English , French , and Hebrew , and demonstrate a significant improvement in identification accuracy , compared with less sophisticated baselines .",O O O O B O B O O B O O O O O O O B B O O O O O O O
Steedman ( 2020 ) proposes as a formal universal of natural language grammar that grammatical permutations of the kind that have given rise to transformational rules are limited to a class known to mathematicians and computer scientists as the “ separable ” permutations .,O O O O O O O O O O B I I O B I O O O O O O O O B I O O O O O O O O O O O O O O O O B O
This class of permutations is exactly the class that can be expressed in combinatory categorial grammars ( CCGs ) .,O O O B O O O O O O O O O B I I O B O O
The excluded non - separable permutations do in fact seem to be absent in a number of studies of crosslinguistic variation in word order in nominal and verbal constructions .,O O O O O B O O O O O O O O O O O O O B I O O O O B O B I O
The number of permutations that are separable grows in the number n of lexical elements in the construction as the Large Schröder Number Sn−1 .,O O O B O O O O O O O O O B I O O O O O B I I B O
"Because that number grows much more slowly than the n ! number of all permutations , this generalization is also of considerable practical interest for computational applications such as parsing and machine translation .",O O O O O O O O O O O O O O B O O O O O O O O O O B I O O B O B I O
"The present article examines the mathematical and computational origins of this restriction , and the reason it is exactly captured in CCG without the imposition of any further constraints .",O O O O O O O B O O O O O O O O O O O O O B O O O O O O O O
Linguistic corpus design is a critical concern for building rich annotated corpora useful in different domains of applications .,B I O O O O O O O O B I O O O O O O O
"For example , speech technologies such as ASR ( Automatic Speech Recognition ) or TTS ( Text - to - Speech ) need a huge amount of speech data to train data - driven models or to produce synthetic speech .",O O O B I O O B O B I I O O B O B I I I I O O O O O O B I O B B I I I O O O B I O
"Collecting data is always related to costs ( recording speech , verifying annotations , etc .",O O O O O O O O B I O O B O O O
") , and as a rule of thumb , the more data you gather , the more costly your application will be .",O O O O O O O O O O O O O O O O O O O O O O O
"Within this context , we present in this article solutions to reduce the amount of linguistic text content while maintaining a sufficient level of linguistic richness required by a model or an application .",O O O O O O O O O O O O O O O B I I O O O O O O B I O O O B O O B O
This problem can be formalized as a Set Covering Problem ( SCP ) and we evaluate two algorithmic heuristics applied to design large text corpora in English and French for covering phonological information or POS labels .,O O O O O O O B I I O B O O O O O B I O O O O B I O O O O O O B I O B I O
The first considered algorithm is a standard greedy solution with an agglomerative / spitting strategy and we propose a second algorithm based on Lagrangian relaxation .,O O O O O O O O O O O O O O O O O O O O O O O O O O
The latter approach provides a lower bound to the cost of each covering solution .,O O O O O O O O O O O O O O O
This lower bound can be used as a metric to evaluate the quality of a reduced corpus whatever the algorithm applied .,O O O O O O O O B O B O O O O O B O O O O O
Experiments show that a suboptimal algorithm like a greedy algorithm achieves good results ; the cost of its solutions is not so far from the lower bound ( about 4.35 % for 3 - phoneme coverings ) .,O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O B I I I O O
"Usually , constraints in SCP are binary ; we proposed here a generalization where the constraints on each covering feature can be multi - valued .",O O O O B O B O O O O O O O O O O O O O O O O O O O
This article describes an approach to Lexical - Functional Grammar ( LFG ) generation that is based on the fact that the set of strings that an LFG grammar relates to a particular acyclic f - structure is a context - free language .,O O O O O O B I I I O B O B O O O O O O O O O O O O O B I O O O O B I I I O O B I I I O
We present an algorithm that produces for an arbitrary LFG grammar and an arbitrary acyclic input f - structure a context - free grammar describing exactly the set of strings that the given LFG grammar associates with that f - structure .,O O O O O O O O O B I O O O B I B I I O B I I I O O O O O O O O O B I O O O B I I O
The individual sentences are then available through a standard context - free generator operating on that grammar .,O O O O O O O O O B I I I O O O O O
The context - free grammar is constructed by specializing the context - free backbone of the LFG grammar for the given f - structure and serves as a compact representation of all generation results that the LFG grammar assigns to the input .,O B I I I O O O O O B I I O O O B I O O O B I I O O O O O O O O O O O O B I O O O O O
"This approach extends to other grammatical formalisms with explicit context - free backbones , such as PATR , and also to formalisms that permit a context - free skeleton to be extracted from richer speciﬁcations .",O O O O O B I O O B I I I O O O B O O O O O O O O B I I O O O O O O O O
It provides a general mathematical framework for understanding and improving the operation of a family of chart - based generation algorithms .,O O O O O O O O O O O O O O O O B I I I I O
"Graphs have a variety of uses in natural language processing , particularly as representations of linguistic meaning .",B O O O O O O B I I O O O O O B I O
"A deficit in this area of research is a formal framework for creating , combining , and using models involving graphs that parallels the frameworks of finite automata for strings and finite tree automata for trees .",O O O O O O O O O B I O O O O O O O B O B O O O O O B I O B O B I I O B O
"A possible starting point for such a framework is the formalism of directed acyclic graph ( DAG ) automata , defined by Kamimura and Slutzki and extended by Quernheim and Knight .",O O O O O O O O O O B O B I I O B O B O O O O O O O O O O O O O
"In this article , we study the latter in depth , demonstrating several new results , including a practical recognition algorithm that can be used for inference and learning with models defined on DAG automata .",O O O O O O O O O O O O O O O O O O B I I O O O O O B O B O B O O B I O
We also propose an extension to graphs with unbounded node degree and show that our results carry over to the extended formalism .,O O O O O O B O B I I O O O O O O O O O B I O
Parsing is a key task in natural language processing .,B O O O O O B I I O
"It involves predicting , for each natural language sentence , an abstract representation of the grammatical entities in the sentence and the relations between these entities .",O O O O O O B I I O O B I O O B I O O O O O O O O O O
This representation provides an interface to compositional semantics and to the notions of “ who did what to whom .,O O O O O O B I O O O O O O O O O O O O
"” The last two decades have seen great advances in parsing English , leading to major leaps also in the performance of applications that use parsers as part of their backbone , such as systems for information extraction , sentiment analysis , text summarization , and machine translation .",O O O O O O O O O O B O O O O O O O O O O O O O O B O O O O O O O O O O B I O B I O B I O O B I O
Attempts to replicate the success of parsing English for other languages have often yielded unsatisfactory results .,O O O O O O B O O O O O O O O O O
"In particular , parsing languages with complex word structure and flexible word order has been shown to require non - trivial adaptation .",O O O B O O O O O O O O O O O O O O O O O O O
This special issue reports on methods that successfully address the challenges involved in parsing a range of morphologically rich languages ( MRLs ) .,O O O O O O O O O O O O O B O O O B I I O B O O
"This introduction characterizes MRLs , describes the challenges in parsing MRLs , and outlines the contributions of the articles in the special issue .",O O O B O O O O O B B O O O O O O O O O O O O O
"These contributions present up - to - date research efforts that address parsing in varied , cross - lingual settings .",O O O O O O O O O O O O B O O O B I I O O
They show that parsing MRLs addresses challenges that transcend particular representational and algorithmic choices .,O O O B B O O O O O O O O O O
We present a new framework for compositional distributional semantics in which the distributional contexts of lexemes are expressed in terms of anchored packed dependency trees .,O O O O B O B I I O O O B I I I O O O O O O O B I O
We show that these structures have the potential to capture the full sentential contexts of a lexeme and provide a uniform basis for the composition of distributional knowledge in a way that captures both mutual disambiguation and generalization .,O O O O O O O O O O O O B I O O B O O O O O O O O O B I O O O O O O O B O B O
This article presents an investigation of corpus based methods for the automation of help desk e mail responses .,O O O O O O B O O O O B O O O O O O O
"Specifically , we investigate this problem along two operational dimensions : ( 1 ) information gathering technique , and ( 2 ) granularity of the information .",O O O O O O O O B I O O O O B I I O O O O O B O O B O
We consider two information gathering techniques ( retrieval and prediction ) applied to information represented at two levels of granularity ( document level and sentence level ) .,O O O B I I O B O B O O O B O O O O O B O B I O B I O O
Document level methods correspond to the reuse of an existing response e mail to address new requests .,B I I O O O O O O O O O O O O O B O
Sentence level methods correspond to applying extractive multi document summarization techniques to collate units of information from more than one e mail .,B I I O O O B I I I I O O B O B O O O O O O O
Evaluation of the performance of the different methods shows that in combination they are able to successfully automate the generation of responses for a substantial portion of e mail requests in our corpus .,B O O O O O O I O O O O O O O O O B O B O B O O B O O O O B O O B O
"We also investigate a meta selection process that learns to choose one method to address a new inquiry e mail , thus providing a unified response automation solution .",O O O O B I I O O O O O I O O O O B O O O O O O B I I I O
"This article presents a new model for word sense disambiguation formulated in terms of evolutionary game theory , where each word to be disambiguated is represented as a node on a graph whose edges represent word relations and senses are represented as classes .",O O O O O B O B I I O O O O O O O O O O B I I I O B I I I I I I O B I I I O B I I I I O
The words simultaneously update their class membership preferences according to the senses that neighboring words are likely to choose .,O B O O O B I O O O O B O O B O O O O O
We use distributional information to weigh the influence that each word has on the decisions of the others and semantic similarity information to measure the strength of compatibility among the choices .,O O B I O B I I O O B O O O O O O O O B I I O O O O O O O O O O
"With this information we can formulate the word sense disambiguation problem as a constraint satisfaction problem and solve it using tools derived from game theory , maintaining the textual coherence .",O O O O O O O B I I O O O B I I O O O O O O O O O O O O B I O
The model is based on two ideas : Similar words should be assigned to similar classes and the meaning of a word does not depend on all the words in a text but just on some of them .,O B O O O O O O B I O O O O B I O O B I I I O O O O O O B I I I O O O O O O O
"The article provides an in - depth motivation of the idea of modeling the word sense disambiguation problem in terms of game theory , which is illustrated by an example .",O O O O O O O O O O O O B I I I I I O O O O O O O O O O O O O
The conclusion presents an extensive analysis on the combination of similarity measures to use in the framework and a comparison with state - of - the - art systems .,O O O O O O O O O O B I O O O O O O O O O B I I I I I I O O
The results show that our model outperforms state - of - the - art algorithms and can be applied to different tasks and in different scenarios .,O O O O O B I B I I I I I I B O O O O O O O O O O O O
"This article gives an overview of how sentence meaning is represented in eleven deep - syntactic frameworks , ranging from those based on linguistic theories elaborated for decades to rather lightweight NLP - motivated approaches .",O O O O O O O B I O O O O B I I I O O O O O O B I O O O O O O B O O O O
"We outline the most important characteristics of each framework and then discuss how particular language phenomena are treated across those frameworks , while trying to shed light on commonalities as well as differences .",O O O O O O O O B O O O O O B I O O O O B O O O O O O O O O O O O O
Human syntactic processing shows many signs of taking place within a general - purpose short - term memory .,O B I O O O O O O O O O O O B I I I O
But this kind of memory is known to have a severely constrained storage capacity — possibly constrained to as few as three or four distinct elements .,O O O O O O O O O O O O B I O O O O O O O O O O O O O
"This article describes a model of syntactic processing that operates successfully within these severe constraints , by recognizing constituents in a right - corner transformed representation ( a variant of left - corner parsing ) and mapping this representation to random variables in a Hierarchic Hidden Markov Model , a factored time - series model which probabilistically models the contents of a bounded memory store over time .",O O O O B O B I O O O O O O O O O O B O O B I I I I O O O O B I I I O O O O O O B I O O B I I I O O B I I I I O O O O O O O B I I O O O
"Evaluations of the coverage of this model on a large syntactically annotated corpus of English sentences , and the accuracy of a a bounded - memory parsing strategy based on this model , suggest this model may be cognitively plausible .",O O O B O O O O O O B I I O O O O O O B O O O B I I I I O O O O O O O O O O B I O
