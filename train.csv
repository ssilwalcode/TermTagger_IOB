sent,tags
"We introduce HyperLex — a data set and evaluation resource that quantifies the extent of the semantic category membership , that is , type - of relation , also known as hyponymy – hypernymy or lexical entailment ( LE ) relation between 2,616 concept pairs .",O O B O O B I O B I O O O O O O B I I O O O O O O O O O O O O B O B O B I O B O O O O B I O
Cognitive psychology research has established that typicality and category / class membership are computed in human semantic memory as a gradual rather than binary relation .,B I O O O O O O B I I I O O O B I I O O B O O B I O
"Nevertheless , most NLP research and existing large - scale inventories of concept category membership ( WordNet , DBPedia , etc .",O O O B O O O B I I I O B I I O B O B O O O
) treat category membership and LE as binary .,O O B I O B O B O
"To address this , we asked hundreds of native English speakers to indicate typicality and strength of category membership between a diverse range of concept pairs on a crowdsourcing platform .",O O O O O O O O B I I O O O O O O B I O O O O O B I O O O O O
Our results confirm that category membership and LE are indeed more gradual than binary .,O O O O B I O B O O O B O B O
"We then compare these human judgments with the predictions of automatic systems , which reveals a huge gap between human performance and state - of - the - art LE , distributional and representation learning models , and substantial differences between the models themselves .",O O O O B I O O B O O O O O O O O O O B I O B I I I I I I B O B O B I I O O O O O O B O O
"We discuss a pathway for improving semantic models to overcome this discrepancy , and indicate future application areas for improved graded LE systems .",O O O O O O B I O O O O O O O O B I O O B I I O
"Noun phrases ( nps ) are a crucial part of natural language , and can have a very complex structure .",B I O B O O O O O O B I O O O O O O O O O
"However , this np structure is largely ignored by the statistical parsing field , as the most widely used corpus is not annotated with it .",O O O B I O O O O O B I I O O O O O O B O O B O O O
"This lack of gold - standard data has restricted previous efforts to parse nps , making it impossible to perform the supervised experiments that have achieved high performance in so many Natural Language Processing ( nlp ) tasks .",O O O B I I O O O O O O B B O O O O O O O B O O O O O O O O O B I I O B O O O
We comprehensively solve this problem by manually annotating np structure for the entire Wall Street Journal section of the Penn Treebank .,O O O O O O O B B O O O O O O O O O O B I O
"The inter - annotator agreement scores that we attain dispel the belief that the task is too difficult , and demonstrate that consistent np annotation is possible .",O B I I I I O O O O O O O O O O O O O O O O O B B O O O
Our gold - standard np data is now available for use in all parsers .,O B I I B O O O O O O O O B O
"We experiment with this new data , applying the Collins ( 2003 ) parsing model , and find that its recovery of np structure is significantly worse than its overall performance .",O O O O O O O O O B O O O I I O O O O O B O B I O O O O O O O O
The parser 's F - score is up to 5.69 % lower than a baseline that uses deterministic rules .,O B O B I I O O O O O O O O B O O B I O
"Through much experimentation , we determine that this result is primarily caused by a lack of lexical information .",O O O O O O O O O O O O O O O O B I O
"To solve this problem we construct a wide - coverage , large - scale np Bracketing system .",O O O O O O O O O O O O O O B B I O
"With our Penn Treebank data set , which is orders of magnitude larger than those used previously , we build a supervised model that achieves excellent results .",O O B I I O O O O O O O O O O O O O O O O B I O O O O O
"Our model performs at 93.8 % F - score on the simple task that most previous work has undertaken , and extends to bracket longer , more complex nps that are rarely dealt with in the literature .",O B O O O O B I I O O O O O O O O O O O O O O B O O O O B O O O O O O O O O
We attain 89.14 % F - score on this much more difficult task .,O O O O B I I O O O O O O O
"Finally , we implement a post - processing module that brackets nps identified by the Bikel ( 2004 ) parser .",O O O O O B I I I O B B O O O O O O O B O
"Our np Bracketing model includes a wide variety of features that provide the lexical information that was missing during the parser experiments , and as a result , we outperform the parser 's F - score by 9.04 % .",O B B I O O O O O O O O O B O O O O O O B O O O O O O O O B O B O B I I O O O O
"These experiments demonstrate the utility of the corpus , and show that many nlp applications can now make use of np structure .",O O O O O O O B O O O O O B O O O O O O B I O
"This article introduces RELPRON , a large data set of subject and object relative clauses , for the evaluation of methods in compositional distributional semantics .",O O O B O O O O O O B I I I I O O O O O O O B I I O
RELPRON targets an intermediate level of grammatical complexity between content - word pairs and full sentences .,B O O O O O B I O B I I I O B I O
"The task involves matching terms , such as “ wisdom , ” with representative properties , such as “ quality that experience teaches .",O O O O O O O O O O O O O B I O O O O O O O O O
"” A unique feature of RELPRON is that it is built from attested properties , but without the need for them to appear in relative clause format in the source corpus .",O O O O O B O O O O O O B I O O O O O O O O O O B I I O O B I O
"The article also presents some initial experiments on RELPRON , using a variety of composition methods including simple baselines , arithmetic operators on vectors , and finally , more complex methods in which argument - taking words are represented as tensors .",O O O O O O O O B O O O O O B I O B I O B I O O O O O O O O O O O O O O O O O O B O
"The latter methods are based on the Categorial framework , which is described in detail .",O O O O O O O B I O O O O O O O
The results show that vector addition is difficult to beat — in line with the existing literature — but that an implementation of the Categorial framework based on the Practical Lexical Function model is able to match the performance of vector addition .,O O O O B I O O O O O O O O O O O O O O O O O O B I O O O B I I I O O O O O O O B I O
"The article finishes with an in - depth analysis of RELPRON , showing how results vary across subject and object relative clauses , across different head nouns , and how the methods perform on the subtasks necessary for capturing relative clause semantics , as well as providing a qualitative analysis highlighting some of the more common errors .",O O O O O O O O O O B O O O O O O B I I I I O O O B I O O O O O O O O O O O O B I I O O O O O O B I O O O O O O O O
"Our hope is that the competitive results presented here , in which the best systems are on average ranking one out of every two properties correctly for a given term , will inspire new approaches to the RELPRON ranking task and other tasks based on linguistically interesting constructions .",O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O B I I O O O O O B O O O
"This article describes the development of Microsoft XiaoIce , the most popular social chatbot in the world .",O O O O O O B I O O O O B I O O O O
"XiaoIce is uniquely designed as an artifical intelligence companion with an emotional connection to satisfy the human need for communication , affection , and social belonging .",B O O O O O B I I O O O O O O O O O O O O O O O O O O
"We take into account both intelligent quotient and emotional quotient in system design , cast human – machine social chat as decision - making over Markov Decision Processes , and optimize XiaoIce for long - term user engagement , measured in expected Conversation - turns Per Session ( CPS ) .",O O O O O B I O B I O O O O O B I I O O O B I I O B I I O O O B O B I I B I O O O O B I I I I O B O O
"We detail the system architecture and key components , including dialogue manager , core chat , skills , and an empathetic computing module .",O O O B I O O O O O B I O B I O O O O O B I I O
"We show how XiaoIce dynamically recognizes human feelings and states , understands user intent , and responds to user needs throughout long conversations .",O O O B O O O O O O O O B I O O O O O O O O O O
"Since the release in 2014 , XiaoIce has communicated with over 660 million active users and succeeded in establishing long - term relationships with many of them .",O O O O O O B O O O O O O O O O O O O B I I B O O O O O
"Analysis of large - scale online logs shows that XiaoIce has achieved an average CPS of 23 , which is significantly higher than that of other chatbots and even human conversations .",O O O O O O O O O B O O O O B O O O O O O O O O O O B O O O O O
"Recent discussions of annotator agreement have mostly centered around its calculation and interpretation , and the correct choice of indices .",O O O B O O O O O O O O O O O O O O O B O
"Although these discussions are important , they only consider the “ back - end ” of the story , namely , what to do once the data are collected .",O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O
"Just as important in our opinion is to know how agreement is reached in the first place and what factors influence coder agreement as part of the annotation process or setting , as this knowledge can provide concrete guidelines for the planning and set - up of annotation projects .",O O O O O O O O O O B O O O O O O O O O O B I O O O O B O O O O O O O O O O O O O O O O O O O O O O
To investigate whether there are factors that consistently impact annotator agreement we conducted a meta - analytic investigation of annotation studies reporting agreement percentages .,O O O O O O O O O B O O O O B I I I O B O O O O O
"Our meta - analysis synthesized factors reported in 96 annotation studies from three domains ( word - sense disambiguation , prosodic transcriptions , and phonetic transcriptions ) and was based on a total of 346 agreement indices .",O B I I O O O O O B O O O O O B I I I O B I O O B I O O O O O O O O O O B O
"Our analysis identified seven factors that influence reported agreement values : annotation domain , number of categories in a coding scheme , number of annotators in a project , whether annotators received training , the intensity of annotator training , the annotation purpose , and the method used for the calculation of percentage agreements .",O O O O O O O O O O O B I O O O O O O B I O O O B O O O O O B O O O O O O B O O O B O O O O O O O O O O O O O
"Based on our results we develop practical recommendations for the assessment , interpretation , calculation , and reporting of coder agreement .",O O O O O O O O O O O O O O O O O O O B O O
We also briefly discuss theoretical implications for the concept of annotation quality .,O O O O O O O O O O B I O
We introduce the Computational Linguistics special issue on Multilingual and Interlingual Semantic Representations for Natural Language Processing .,O O O B I O O O B O B I I O B I I O
"We situate the special issue ’s five articles in the context of our fast - changing field , explaining our motivation for this project .",O O O O O O O O O O O O O O O O O O O O O O O O O
"We offer a brief summary of the work in the issue , which includes developments on lexical and sentential semantic representations , from symbolic and neural perspectives .",O O O O O O O O O O O O O O O O B O B I I O O O O B I O
This article shows that the structure of bilingual material from standard parsing and alignment tools is not optimal for training syntax - based statistical machine translation ( SMT ) systems .,O O O O O O O B I O B I O B I O O O O O B I I I I I O B O I O
We present three modifications to the MT training data to improve the accuracy of a state - of - the - art syntax MT system : re - structuring changes the syntactic structure of training parse trees to enable reuse of substructures ; re - labeling alters bracket labels to enrich rule application context ; and re - aligning unifies word alignment across sentences to remove bad word alignments and refine good ones .,O O O O O O B I I O O O B O O B I I I I I I B I I O B I I O O B I O B B I O O O O B O B I I O B I O O B I I O O B I I O B I O O O O O B I O O O O O
"Better structures , labels , and word alignments are learned by the EM algorithm .",O B O B O O B I O O O O B I O
"We show that each individual technique leads to improvement as measured by BLEU , and we also show that the greatest improvement is achieved by combining them .",O O O O O O O O O O O O B O O O O O O O O O O O O O O O
We report an overall 1.48 BLEU improvement on the NIST08 evaluation set over a strong baseline in Chinese / English translation .,O O O O O B I O O B I I O O O B O O O O B O
Modeling compositional meaning for sentences using empirical distributional methods has been a challenge for computational linguists .,B I O O B O B I I O O O O O B I O
"The categorical model of Clark , Coecke , and Sadrzadeh ( 2008 ) and Coecke , Sadrzadeh , and Clark ( 2010 ) provides a solution by unifying a categorial grammar and a distributional model of meaning .",O B I O O O O O O O O O O O O O O O O O O O O O O O O O O B I O O B I O O O
It takes into account syntactic relations during semantic vector composition operations .,O O O O B I O B I I I O
But the setting is abstract : It has not been evaluated on empirical data and applied to any language tasks .,O O O O O O O O O O O O B I O O O O B I O
We generate concrete models for this setting by developing algorithms to construct tensors and linear maps and instantiate the abstract parameters using empirical data .,O O O B O O O O O O O O B O B I O O O B I O B I O
"We then evaluate our concrete models against several experiments , both existing and new , based on measuring how well models align with human judgments in a paraphrase detection task .",O O O O O B O O O O O O O O O O O O O O B O O O O O O B I I O
Our results show the implementation of this general abstract framework to perform on par with or outperform other leading models in these experiments .,O O O O O O O O O O O O O O O O O O O B O O O O
Probabilistic grammars are generative statistical models that are useful for compositional and sequential structures .,B I O B I I O O O O B O B I O
They are used ubiquitously in computational linguistics .,O O O O O B I O
"We present a framework , reminiscent of structural risk minimization , for empirical risk minimization of probabilistic grammars using the log - loss .",O O O O O O O B I I O O B I I O B I O O B I I O
We derive sample complexity bounds in this framework that apply both to the supervised setting and the unsupervised setting .,O O B I I O O O O O O O O B I O O B I O
"By making assumptions about the underlying distribution that are appropriate for natural language scenarios , we are able to derive distribution - dependent sample complexity bounds for probabilistic grammars .",O O O O O B I O O O O B I I O O O O O O B I I I I I O B I O
We also give simple algorithms for carrying out empirical risk minimization using this framework in both the supervised and unsupervised settings .,O O O O O O O O B I I O O O O O O B O B I O
"In the unsupervised case , we show that the problem of minimizing empirical risk is NP - hard .",O O B O O O O O O O O O B I O B I I O
"We therefore suggest an approximate algorithm , similar to expectation - maximization , to minimize the empirical risk .",O O O O B I O O O O O O O O O O B I O
We describe a computational model for planning phrases like “ more than a quarter ” and “ 25.9 per cent ” which describe proportions at different levels of precision .,O O O B I O O O O O O O O O O O O O O O O O O O O O O O O O
"The model lays out the key choices in planning a numerical description , using formal deﬁnitions of mathematical form ( e.g. , the distinction between fractions and percentages ) and roundness adapted from earlier studies .",O O O O O O O O O O B I O O B I O O O O O O O O O O O O O O B O O O O O
"The task is modeled as a constraint satisfaction problem , with solutions subsequently ranked by preferences ( e.g. , for roundness ) .",O O O O O O B I I O O O O O O O O O O O B O O
"Detailed constraints are based on a corpus of numerical expressions collected in the N UM G EN project , 1 and evaluated through empirical studies in which subjects were asked to produce ( or complete ) numerical expressions in speciﬁed contexts .",O O O O O O B O B I O O O O O O O O O O O O O O O O O O O O O O O O O O B I O O O O
"We present a series of studies of afﬁrmative cue words — a family of cue words such as “ okay ” or “ alright "" that speakers use frequently in conversation .",O O O O O O O O B I O O O O B I O O O O O O O O O O O O O O O O
"These words pose a challenge for spoken dialogue systems because of their ambiguity : They may be used for agreeing with what the interlocutor has said , indicating continued attention , or for cueing the start of a new topic , among other meanings .",O O O O O O B I I O O O O O O O O O O O O O O O O O O O B I O O O O O O O O O O O O O O O
"We describe differences in the acoustic / prosodic realization of such functions in a corpus of spontaneous , task - oriented dialogues in Standard American English .",O O O O O B O B I O O O O O O O O O B I I I O O O O O
These results are important both for interpretation and for production in spoken language applications .,O O O O O O O O O O O B I I O
We also assess the predictive power of computational methods for the automatic disambiguation of these words .,O O O O O O O B I O O B I O O O O
We ﬁnd that contextual information and ﬁnal intonation ﬁgure as the most salient cues to automatic disambiguation .,O O O B I O B I I O O O B I O B I O
"Identifying the veracity , or factuality , of event mentions in text is fundamental for reasoning about eventualities in discourse .",O O O O O O O O O O O O O O O O O O O B O
"Inferences derived from events judged as not having happened , or as being only possible , are different from those derived from events evaluated as factual .",B O O O O O O O O O O O O O O O O O O O O O O O O O O
Event factuality involves two separate levels of information .,B I O O O O O O O
"On the one hand , it deals with polarity , which distinguishes between positive and negative instantiations of events .",O O O O O O O O O O O O O O O B I O O O
"On the other , it has to do with degrees of certainty ( e.g. , possible , probable ) , an information level generally subsumed under the category of epistemic modality .",O O O O O O O O O B I I O O O O O O O O O B I O O O O O O B I O
This article aims at contributing to a better understanding of how event factuality is articulated in natural language .,O O O O O O O O O O O B I O O O B I O
"For that purpose , we put forward a linguistic - oriented computational model which has at its core an algorithm articulating the effect of factuality relations across levels of syntactic embedding .",O O O O O O O O B I I I I O O O O O O O O O O O B I O O O B I O
"As a proof of concept , this model has been implemented in De Facto , a factuality proﬁler for eventualities mentioned in text , and tested against a corpus built speciﬁcally for the task , yielding an F 1 of 0.70 ( macro - averaging ) and 0.80 ( micro - averaging ) .",O O O O O O O O O O O O B I O O B I O O O O O O O O O O O O O O O O O O O B I O O O B I I O O O O B I I O O
"These two measures mutually compensate for an over - emphasis present in the other ( either on the lesser or greater populated categories ) , and can therefore be interpreted as the lower and upper bounds of the De Facto ’s performance .",O O O O O O O O O O O O O O O O O O O O O B I O O O O O O O O O O O B I O O B I O O O
Multilingual representations have mostly been evaluated based on their performance on specific tasks .,B I O O O O O O O O O O O O
"In this article , we look beyond engineering goals and analyze the relations between languages in computational representations .",O O O O O O O O O O O O O O O O B I O
We introduce a methodology for comparing languages based on their organization of semantic concepts .,O O O O O O O O O O O O B I O
We propose to conduct an adapted version of representational similarity analysis of a selected set of concepts in computational multilingual representations .,O O O O O O O O B I I O O O O O O O B I I O
"Using this analysis method , we can reconstruct a phylogenetic tree that closely resembles those assumed by linguistic experts .",O O O O O O O O O B I O O O O O O B I O
These results indicate that multilingual distributional representations that are only trained on monolingual text and bilingual dictionaries preserve relations between languages without the need for any etymological information .,O O O O B I I O O O O O B I O B I O O O O O O O O O B I O
"In addition , we propose a measure to identify semantic drift between language families .",O O O O O O O O O B I O B I O
We perform experiments on word - based and sentence - based multilingual models and provide both quantitative results and qualitative examples .,O O O O B I I O B I I I I O O O O O O O O O
Analyses of semantic drift in multilingual representations can serve two purposes : They can indicate unwanted characteristics of the computational models and they provide a quantitative means to study linguistic phenomena across languages .,B I I I O B I O O O O O O O O O O O O B I O O O O O O O O B I I I O
"Highly frequent in language and communication , metaphor represents a significant challenge for Natural Language Processing ( NLP ) applications .",O O O B O B O B O O O O O B I I O B O I O
"Computational work on metaphor has traditionally evolved around the use of hand - coded knowledge , making the systems hard to scale .",B I I I O O O O O O O O O O O O O O O O O O O
Recent years have witnessed a rise in statistical approaches to metaphor processing .,O O O O O O O B I O B I O
"However , these approaches often require extensive human annotation effort and are predominantly evaluated within a limited domain .",O O O O O O B I I O O O O O O O O O O
"In contrast , we experiment with weakly supervised and unsupervised techniques — with little or no annotation — to generalize higher - level mechanisms of metaphor from distributional properties of concepts .",O O O O O O O B O B I O O O O O B O O O O O O O O B O B I I I O
"We investigate different levels and types of supervision ( learning from linguistic examples vs. learning from a given set of metaphorical mappings vs. learning without annotation ) in flat and hierarchical , unconstrained and constrained clustering settings .",O O O O O O O B O B O B O O B O O O O O B I O B I I O O O O O O O O O B I O
Our aim is to identify the optimal type of supervision for a learning algorithm that discovers patterns of metaphorical association from text .,O O O O O O O B I I O O B I O B I O B I B I O
"In order to investigate the scalability and adaptability of our models , we applied them to data in three languages from different language groups — English , Spanish , and Russian — achieving state - of - the - art results with little supervision .",O O O O O B O B O O B O O O O O B I I I O B I I O B O B O O B O O B I I I I II I O O B I O
"Finally , we demonstrate that statistical methods an facilitate and scale up cross - linguistic research on metaphor .",O O O O O B I O O O B I B I I O O B O
"Universal dependencies ( UD ) is a framework for morphosyntactic annotation of human language , which to date has been used to create treebanks for more than 100 languages .",B I O B O O O O O B I O O O O O O O O O O O O B O O O O O O
"In this article , we outline the linguistic theory of the UD framework , which draws on a long tradition of typologically oriented grammatical theories .",O O O O O O O O O O O B I O O O O O O O O B I I O O
Grammatical relations between words are centrally used to explain how predicate – argument structures are encoded morphosyntactically in different languages while morphological features and part - of - speech classes give the properties of words .,O O O O O O O O O O B I I I O B B O O O O B I O B I I I I O O O B O O O
We argue that this theory is a good basis for crosslinguistically consistent annotation of typologically diverse languages in a way that supports computational natural language understanding as well as broader linguistic studies .,O O O O O O O O O O B I I O B I O O O O O O B I I I O O O O O O O
"We borrow the concept of representation learning from deep learning research , and we argue that the quest for Greenbergian implicational universals can be reformulated as the learning of good latent representations of languages , or sequences of surface typological features .",O O O O O B I O B I O O O O O O O O O B I I O O O O O O O O B I O O O O O O B I I O
"By projecting languages into latent representations and performing inference in the latent space , we can handle complex dependencies among features in an implicit manner .",O O O O B I O O B O O B I O O O O O O O O O O O O O
The most challenging problem in turning the idea into a concrete computational model is the alarmingly large number of missing values in existing typological databases .,O O O O O O O O O O O B I O O O O O O O O O O B I O
"To address this problem , we keep the number of model parameters relatively small to avoid overfitting , adopt the Bayesian learning framework for its robustness , and exploit phylogenetically and/or spatially related languages as additional clues .",O O O O O O O O O O B I O O O O B O O O B I O O O O O O O B O B I I O O O O
Experiments show that the proposed model recovers missing values more accurately than others and that some latent variables exhibit phylogenetic and spatial signals comparable to those of surface features .,O O O O O O O O O O O O O O O O B O O B O O O O O O O O O O
"This article presents our work on constructing a corpus of news articles in which events are annotated for estimated bounds on their duration , and automatically learning from this corpus .",O O O O O O O O B O O O O O O O B O O O O O O O O O B O O B O
"We describe the annotation guidelines , the event classes we categorized to reduce gross discrepancies in inter - annotator judgments , and our use of normal distributions to model vague and implicit temporal information and to measure inter - annotator agreement for these event duration distributions .",O O O B I O O O O O O O O O O O B I I I O O O O O B I O O O O O O O O O O B I I I O O O O O O
"We then show that machine learning techniques applied to this data can produce coarse - grained event duration information automatically , considerably outperforming a baseline and approaching human performance .",O O O O B I O O O O O O O O O O O O O O O O B O B O O O O O
The methods described here should be applicable to other kinds of vague but substantive information in texts .,O O O O O O O O O O O O O O O O O O
"The goal of argumentation mining , an evolving research field in computational linguistics , is to design methods capable of analyzing people 's argumentation .",O O O B I O O O O O O B I O O O O O O O O O O B O
"In this article , we go beyond the state of the art in several ways .",O O O O O O O O B I I I O O O O
"( i ) We deal with actual Web data and take up the challenges given by the variety of registers , multiple domains , and unrestricted noisy user - generated Web discourse .",O O O O O O O B I O O O O O O O O O O O O O O O O O O O O B I I O
( ii ) We bridge the gap between normative argumentation theories and argumentation phenomena encountered in actual data by adapting an argumentation model tested in an extensive annotation study .,O O O O O O O O B I O O B O O O O B O B I I I O O O O B O O
( iii ) We create a new gold standard corpus ( 90k tokens in 340 documents ) and experiment with several machine learning methods to identify argument components .,O O O O O O O B I I O O B O O B O O O O O B I I O B I I O
"We offer the data , source codes , and annotation guidelines to the community under free licenses .",O O O B O B O O O B I O O O O O O O
Our findings show that argumentation mining in user - generated Web discourse is a feasible but challenging task .,O O O O B I O B I I I I O O O O O O O
"In this article we address the task of cross - lingual sentiment lexicon learning , which aims to automatically generate sentiment lexicons for the target languages with available English sentiment lexicons .",O O O O O O O O B I I I I I O O O O B I I I O O B I O O O B I O
"We formalize the task as a learning problem on a bilingual word graph , in which the intra - language relations among the words in the same language and the inter - language relations among the words between different languages are properly represented .",O O O O O O B I O O B I I O O O O B I I I O O B O O O B O O B I I I O O B O O O O O O O
"With the words in the English sentiment lexicon as seeds , we propose a bilingual word graph label propagation approach to induce sentiment polarities of the unlabeled words in the target language .",O O B O O O B I O B O O O O B I I I B I O O B I O O B I O O B I O
"Particularly , we show that both synonym and antonym word relations can be used to build the intra - language relation , and that the word alignment information derived from bilingual parallel sentences can be effectively leveraged to build the inter - language relation .",O O O O O O B O B I I O O O O O O B I I I O O O O B I I B O B I I O O O O O O O B I I I O
The evaluation of Chinese sentiment lexicon learning shows that the proposed approach outperforms existing approaches in both precision and recall .,O B O O B I I O O O O O O O O O O B O B O
Experiments conducted on the NTCIR data set further demonstrate the effectiveness of the learned sentiment lexicon in sentence - level sentiment classification .,O O O O B I I O O O O O O B I I O B I I I I O
"Logical negation is a challenge for distributional semantics , because predicates and their negations tend to occur in very similar contexts , and consequently their distributional vectors are very similar .",B I O O O O B I O O B O O B O O O O O O O O O O O B I O O O O
"Indeed , it is not even clear what properties a “ negated ” distributional vector should possess .",O O O O O O O O O O B I I I I O O O
"However , when linguistic negation is considered in its actual discourse usage , it often performs a role that is quite different from straightforward logical negation .",O O O B I O O O O O B I O O O O O O O O O O O O B I O
"If someone states , in the middle of a conversation , that “ This is not a dog , ” the negation strongly suggests a restricted set of alternative predicates that might hold true of the object being talked about .",O O O O O O O O O O O O O O O O O O O O O B O O O O O O O O O O O O O O O O O O O
"In particular , other canids and middle - sized mammals are plausible alternatives , birds are less likely , skyscrapers and other large buildings virtually impossible .",O O O O O O O O O O O O O O O O O O O O O O O O O O O
"Conversational negation acts like a graded similarity function , of the sort that distributional semantics might be good at capturing .",B I O O O B I I O O O O O B I O O O O O O
"In this article , we introduce a large data set of alternative plausibility ratings for conversationally negated nominal predicates , and we show that simple similarity in distributional semantic space provides an excellent fit to subject data .",O O O O O O O O O O O O B I O B I I I O O O O O O O O B I I O O O O O B I O
"On the one hand , this fills a gap in the literature on conversational negation , proposing distributional semantics as the right tool to make explicit predictions about potential alternatives of negated predicates .",O O O O O O O O O O O O O B I O O B I O O O O O O B I O O O O B I O
"On the other hand , the results suggest that negation , when addressed from a broader pragmatic perspective , far from being a nuisance , is an ideal application domain for distributional semantic methods .",O O O O O O O O O B O O O O O O O O O O O O O O O O O O O O O B I I O
We study the problem of response selection for multi - turn conversation in retrieval - based chatbots .,O O O O O B I O B I I I O B I I I O
"The task involves matching a response candidate with a conversation context , the challenges for which include how to recognize important parts of the context , and how to model the relationships among utterances in the context .",O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O B O O O O
Existing matching methods may lose important information in contexts as we can interpret them with a unified framework in which contexts are transformed to fixed - length vectors without any interaction with responses before matching .,O O O O O O O O O O O O O O O O B I O O O O O O O O O B O O O O O O O O
This motivates us to propose a new matching framework that can sufficiently carry important information in contexts to matching and model relationships among utterances at the same time .,O O O O O O O B I O O O O O O O O O O O O O O O O O O O O
"The new framework , which we call a sequential matching framework ( SMF ) , lets each utterance in a context interact with a response candidate at the first step and transforms the pair to a matching vector .",O O B O O O O O B I I I I I O O O O O O O O O O O O O O O O O O O O O O O B O
The matching vectors are then accumulated following the order of the utterances in the context with a recurrent neural network ( RNN ) that models relationships among utterances .,O O B O O O O O O O O B O O O O O B I I I I I O O O O B O
Context - response matching is then calculated with the hidden states of the RNN .,B I I I O O O O O B I O O B O
"Under SMF , we propose a sequential convolutional network and sequential attention network and conduct experiments on two public data sets to test their performance .",O B O O O O B I I O B I I O O O O O O B I O O O O O
Experiment results show that both models can significantly outperform state - of - the - art matching methods .,O O O O O B O O O B I I I I I I O O O
We also show that the models are interpretable with visualizations that provide us insights on how they capture and leverage important information in contexts for matching .,O O O O O B O O O O O O O O O O O O O O O O O O O O O
"We explore the concept of hybrid grammars , which formalize and generalize a range of existing frameworks for dealing with discontinuous syntactic structures .",O O O O O B I O O B O B O O O B I O O O B I I O
Covered are both discontinuous phrase structures and non - projective dependency structures .,O O O B I I O B I I I I O
"Technically , hybrid grammars are related to synchronous grammars , where one grammar component generates linear structures and another generates hierarchical structures .",O O B I O O O B I O O O B I O B I O O O B I O
"By coupling lexical elements of both components together , discontinuous structures result .",O O B I O O B O O B I O O
Several types of hybrid grammars are characterized .,O O O B I O O O
We also discuss grammar induction from treebanks .,O O O B I O B O
The main advantage over existing frameworks is the ability of hybrid grammars to separate discontinuity of the desired structures from time complexity of parsing .,O O O O O B O O O O B I O O B O O O B O B I I I O
"This permits exploration of a large variety of parsing algorithms for discontinuous structures , with different properties .",O O O O O O O O B I O B I O O O O O
"This is confirmed by the reported experimental results , which show a wide variety of running time , accuracy , and frequency of parse failures .",O O O O O O O O O O O O O O O B I O B O O B I I I O
Recent research has shown clear improvement in translation quality by exploiting linguistic syntax for either the source or target language .,O O O O O O O B I O O B I O O O O O B I O
"However , when using syntax for both languages ( “ tree - to - tree ” translation ) , there is evidence that syntactic divergence can hamper the extraction of useful rules ( Ding and Palmer 2005 ) .",O O O O B O O B O O B I I I I O B O O O O O O B I O O O B O O O O O O O O O O
"Smith and Eisner ( 2006 ) introduced quasi - synchronous grammar , a formalism that treats non - isomorphic structure softly using features rather than hard constraints .",O O O O O O O B O B I O O B O O O O B I O O B O O O O O
"Although a natural fit for translation modeling , its flexibility has proved challenging for building real - world systems .",O O B I O B I O O O O O O O O O O O O O
"In this article , we present a tree - to - tree machine translation system inspired by quasi - synchronous grammar .",O O O O O O O O O O O O B I O O O B I I I O
"The core of our approach is a new model that combines phrases and dependency syntax , integrating the advantages of phrase - based and syntax - based translation .",O O O O O O O O O O O B O B I O O O O O B I I O B I I I O
We report statistically significant improvements over a phrase - based baseline on five of seven test sets across four language pairs .,O O O O O O O B I I I O O O O O O O O B I O
We also present encouraging preliminary results on the use of unsupervised dependency parsing for syntax - based machine translation .,O O O O O O O O O O B I I O B I I I I O
Sound correspondence patterns play a crucial role for linguistic reconstruction .,B I I O O O O O B I O
"Linguists use them to prove language relationship , to reconstruct proto - forms , and for classical phylogenetic reconstruction based on shared innovations .",B O O O O B I O O O B O I O O O O B I O O O O O
"Cognate words that fail to conform with expected patterns can further point to various kinds of exceptions in sound change , such as analogy or assimilation of frequent words .",B I O O O O O O O O O O O O O O O O B I O O O B O B O O O O
Here I present an automatic method for the inference of sound correspondence patterns across multiple languages based on a network approach .,O O O O O O O O O O B I I O O O O O O B I O
The core idea is to represent all columns in aligned cognate sets as nodes in a network with edges representing the degree of compatibility between the nodes .,O O O O O O O O O B I I O B O O B O B O O O O O O O B O
"The task of inferring all compatible correspondence sets can then be handled as the well - known minimum clique cover problem in graph theory , which essentially seeks to split the graph into the smallest number of cliques in which each node is represented by exactly one clique .",O O O O O B I I O O O O O O O O O B I I I O B I O O O O O O O B O O O O O B O O O B O O O O O B O
The resulting partitions represent all correspondence patterns that can be inferred for a given data set .,O O O O O B I O O O O O O O O O O
"By excluding those patterns that occur in only a few cognate sets , the core of regularly recurring sound correspondences can be inferred .",O O O O O O O O O O B I O O O O O O B I O O O O
"Based on this idea , the article presents a method for automatic correspondence pattern recognition , which is implemented as part of a Python library which supplements the article .",O O O O O O O O O O O B I I I O O O O O O O O O O O O O O O
"To illustrate the usefulness of the method , I present how the inferred patterns can be used to predict words that have not been observed before .",O O O O O O O O O O O O O O O O O O O O O O O O O O O
"There is growing interest in using automatically computed corpus based evaluation metrics to evaluate Natural Language Generation ( NLG ) systems , because these are often considerably cheaper than the human based evaluations which have traditionally been used in NLG .",O O O O O O B I I I I I O O B I I O B O O O O O O O O O O O O O O O O O O O O B O
"We review previous work on NLG evaluation and on validation of automatic metrics in NLP , and then present the results of two studies of how well some metrics which are popular in other areas of NLP ( notably BLEU and ROUGE ) correlate with human judgments in the domain of computer generated weather forecasts .",O O O O O B I O O B O B I O B O O O O O O O O O O O O O B O O O O O O O B O O B O B O O O O O O O O O O O O O O
"Our results suggest that , at least in this domain , metrics may provide a useful measure of language quality , although the evidence for this is not as strong as we would ideally like to see ; however , they do not provide a useful measure of content quality .",O O O O O O O O O O O B O O O O B O B I O O O O O O O O O O O O O O O O O O O O O O O O O O B O O O O
We also discuss a number of caveats which must be kept in mind when interpreting this and other validation studies .,O O O O O O O O O O O O O O O O O O B I O
"Traditionally , most research in NLP has focused on propositional aspects of meaning .",O O O O O B O O O B I O O O
"To truly understand language , however , extra - propositional aspects are equally important .",O O O O O O O B I I I O O O O
Modality and negation typically contribute signiﬁcantly to these extra - propositional meaning aspects .,O O O O O O O O B I I I I O
"Although modality and negation have often been neglected by mainstream computational linguistics , interest has grown in recent years , as evidenced by several annotation projects dedicated to these phenomena .",O O O O O O O O O O B I O O O O O O O O O O O O O O O O O O O
"Researchers have started to work on modeling factuality , belief and certainty , detecting speculative sentences and hedging , identifying contradictions , and determining the scope of expressions of modality and negation .",O O O O O O B O O O O O O O B I O O O O O O O O O O O O O B O B O
"In this article , we will provide an overview of how modality and negation have been modeled in computational linguistics .",O O O O O O O O O O O B O B O O O O B I O
We report our work on building linguistic resources and data - driven parsers in the grammatical relation ( GR ) analysis for Mandarin Chinese .,O O O O O O O O O O O O B O O B I O B O I O O O O
"Chinese , as an analytic language , encodes grammatical information in a highly configurational rather than morphological way .",O O O O B I O B B I O O O B O O B O O
"Accordingly , it is possible and reasonable to represent almost all grammatical relations as bilexical dependencies .",O O O O O O O O O O O B I O B I O
"In this work , we propose to represent grammatical information using general directed dependency graphs .",O O O O O O O O B I O B I I I O
Both only - local and rich long - distance dependencies are explicitly represented .,O O O O O O B I I I O O O O
"To create high - quality annotations , we take advantage of an existing TreeBank , namely , Chinese TreeBank ( CTB ) , which is grounded on the Government and Binding theory .",O O O O O B O O O O O O O B O O O B I O B O O O O O O O B O B I O
We define a set of linguistic rules to explore CTB ’s implicit phrase structural information and build deep dependency graphs .,O O O O O B I O O B O O B I I O O B I I O
The reliability of this linguistically motivated GR extraction procedure is highlighted by manual evaluation .,O O O O O O B B I O O O B I O
"Based on the converted corpus , data - driven , including graph- and transition - based , models are explored for Chinese GR parsing .",O O O B I O B O I O O B O B O I O O O O O O B I O
"For graph - based parsing , a new perspective , graph merging , is proposed for building flexible dependency graphs : constructing complex graphs via constructing simple subgraphs .",O B O I I O O O O O B I O O O O O O B I O O B I O O O B O
"Two key problems are discussed in this perspective : ( 1 ) how to decompose a complex graph into simple subgraphs , and ( 2 ) how to combine subgraphs into a coherent complex graph .",O O O O O O O O O O O O O O O O I B O I B O O O O O O O O B O O O B I O
"For transition - based parsing , we introduce a neural parser based on a list - based transition system .",O B O I I O O O O B I O O O B O I I I O
"We also discuss several other key problems , including dynamic oracle and beam search for neural transition - based parsing .",O O O O O O O O O B I O B I O B I O I I O
Evaluation gauges how successful GR parsing for Chinese can be by applying data - driven models .,O O O O B I O O O O O O B O I I O
The empirical analysis suggests several directions for future study .,O B I O O O O O O O
"The written form of the Arabic language , Modern Standard Arabic ( MSA ) , differs in a non - trivial manner from the various spoken regional dialects of Arabic — the true “ native languages ” of Arabic speakers .",O O O O O B I O B I I O B O O O O O O O O O O O O B I I O B O O O O B B O O B I O
"Those dialects , in turn , differ quite a bit from each other .",O O O O O O O O O O O O O O
"However , due to MSA 's prevalence in written form , almost all Arabic data sets have predominantly MSA content .",O O O O B O O O B I O O O B B I O O B O O
"In this article , we describe the creation of a novel Arabic resource with dialect annotations .",O O O O O O O O O O O B O O B B O
We have created a large monolingual data set rich in dialectal Arabic content called the Arabic On - line Commentary Data set ( Zaidan and Callison - Burch 2011 ) .,O O O O O B I I O O B B O O O B I I I I B I O O O O O O O O O
"We describe our annotation effort to identify the dialect level ( and dialect itself ) in each of more than 100000 sentences from the data set by crowdsourcing the annotation task , and delve into interesting annotator behaviors ( like over - identification of one 's own dialect ) .",O O O B O O O O B I O O B O O O O O O O O B O O B O O B O B I O O O O O B O O O O O B O O O O B O O
"Using this new annotated data set , we consider the task of Arabic dialect identification : Given the word sequence forming an Arabic sentence , determine the variety of Arabic in which it is written .",O O O B B I O O O O O O B I I O O O B B O O B B O O O O O B O O O O O O
"We use the data to train and evaluate automatic classifiers for dialect identification , and establish that classifiers using dialectal data significantly and dramatically outperform baselines that use MSA - only data , achieving near - human classification accuracy .",O O O B O B O B B I O B I O O O O B O B B O O O O O O O B O O B O O O O O B B O
"Finally , we apply our classifiers to discover dialectical data from a large Web crawl consisting of 3.5 million pages mined from on - line Arabic newspapers .",O O O O O B O O B I O O O B I O O O O O O O O O O B O O
Transformer - based language models have taken many fields in NLP by storm .,B I I B I O O O O O B O O O
"BERT and its derivatives dominate most of the existing evaluation benchmarks , including those for Word Sense Disambiguation ( WSD ) , thanks to their ability in capturing context - sensitive semantic nuances .",B O O O O O O O O O O O O O O B I I O B O O O O O O O O B I I I O O
"However , there is still little knowledge about their capabilities and potential limitations in encoding and recovering word senses .",O O O O O O O O O O O O O O B O O B I O
"In this article , we provide an in - depth quantitative and qualitative analysis of the celebrated BERT model with respect to lexical ambiguity .",O O O O O O O O O O O O O O O O O B I O O O B I O
"One of the main conclusions of our analysis is that BERT can accurately capture high - level sense distinctions , even when a limited number of examples is available for each word sense .",O O O O O O O O O O B O O O B I I I I O O O O O O O O O O O O B I O
Our analysis also reveals that in some cases language models come close to solving coarse - grained noun disambiguation under ideal conditions in terms of availability of training data and computing resources .,O O O O O O O O B I O O O O B I I B I O O O O O O O O B I O B I O
"However , this scenario rarely occurs in real - world settings and , hence , many practical challenges remain even in the coarse - grained setting .",O O O O O O O O O O O O O O O O O O O O O O B I I O O
"We also perform an in - depth comparison of the two main language model - based WSD strategies , namely , fine - tuning and feature extraction , finding that the latter approach is more robust with respect to sense bias and it can better exploit limited available training data .",O O O O O O O O O O O O B I I I B I O O O B I I O B I O O O O O O O O O O O O B I O O O O O O O B I O
"In fact , the simple feature extraction strategy of averaging contextualized embeddings proves robust even using only three training sentences per word sense , with minimal improvements obtained by increasing the size of this training data .",O O O O O B I I O O B I O O O O O O B O O B I O O O O O O O O O O O B I O
"Formalizing “ meaning as context ” mathematically leads to a new , algebraic theory of meaning , in which composition is bilinear and associative .",O O O O O O O O O O O O B I O O O O O O O O O O O
"These properties are shared by other methods that have been proposed in the literature , including the tensor product , vector addition , pointwise multiplication , and matrix multiplication .",O O O O O O O O O O O O O O O O O B I O B I O B I O O B I O
"Entailment can be represented by a vector lattice ordering , inspired by a strengthened form of the distributional hypothesis , and a degree of entailment is deﬁned in the form of a conditional probability .",B O O O O O B I I O O O O O O O O B I O O O B I I O O O O O O O B I O
"Approaches to the task of recognizing textual entailment , including the use of subsequence matching , lexical entailment probability , and latent Dirichlet allocation , can be described within our framework .",O O O O O O B I O O O O O B I O B I I O O B I I O O O O O O O O
"Crosslingual word embeddings learned from monolingual embeddings have a crucial role in many downstream tasks , ranging from machine translation to transfer learning .",B I I O O B I O O O O O O B I O O O B I O B I O
Adversarial training has shown impressive success in learning crosslingual embeddings and the associated word translation task without any parallel data by mapping monolingual embeddings to a shared space .,B I O O O O O O B I O O B I I I O O B I O B B I O O O O O
"However , recent work has shown superior performance for non - adversarial methods in more challenging language pairs .",O O O O O O O O O B I I I O O O B I O
"In this article , we investigate adversarial autoencoder for unsupervised word translation and propose two novel extensions to it that yield more stable training and improved results .",O O O O O O B I O B I I O O O O O O O O O O O O O O O O
"Our method includes regularization terms to enforce cycle consistency and input reconstruction , and puts the target encoders as an adversary against the corresponding discriminator .",O O O B I O B B I O B I O O O O B I O O B O O O B O
"We use two types of refinement procedures sequentially after obtaining the trained encoders and mappings from the adversarial training , namely , refinement with Procrustes solution and refinement with symmetric re - weighting .",O O O O O B I O O O O B I O B O O B I O O O B O B I O B O B I I I O
Extensive experimentations with high- and low - resource languages from two different data sets show that our method achieves better performance than existing adversarial and non - adversarial approaches and is also competitive with the supervised system .,O O O O O B I I I O O O B I O O O O O O O O O B O B I I I O O O O O O B O O
"Along with performing comprehensive ablation studies to understand the contribution of different components of our adversarial model , we also conduct a thorough analysis of the refinement procedures to understand their effects .",O O O B I I O O O O O O O O O B I O O O O O O O O O B I O O O O O
We consider the task of crosslingual semantic parsing in the style of Discourse Representation Theory ( DRT ) where knowledge from annotated corpora in a resource - rich language is transferred via bitext to guide learning in other languages .,O O O O O B I I O O O O B I I O B O O O O B I O O O O O B O O O B O O O O O O O
"We introduce 𝕌niversal Discourse Representation Theory ( 𝕌DRT ) , a variant of DRT that explicitly anchors semantic representations to tokens in the linguistic input .",O O B I I I O B O O O O O B O O O B I O B O O B I O
We develop a semantic parsing framework based on the Transformer architecture and utilize it to obtain semantic resources in multiple languages following two learning schemes .,O O O B I I O O O B I O O O O O B I O B I O O O O O
"The many - to - one approach translates non - English text to English , and then runs a relatively accurate English parser on the translated text , while the one - to - many approach translates gold standard English to non - English text and trains multiple parsers ( one per language ) on the translations .",O B I I I I I O O O O O O O O O O O O O O O B O O O O O O O B I I I I I O B I I O O O O O O B O B O O O O O O O O O
Experimental results on the Parallel Meaning Bank show that our proposal outperforms strong baselines by a wide margin and can be used to construct ( silver - standard ) meaning banks for 99 languages .,O O O O B I I O O O O O B I O O O O O O O O O O O B I I O B I O O O O
Identifying entailment relations between predicates is an important part of applied semantic inference .,O B I O O O O O O O B I I O
In this article we propose a global inference algorithm that learns such entailment rules .,O O O O O O B I I O O O B I O
"First , we deﬁne a graph structure over predicates that represents entailment relations as directed edges .",O O O O O B I O O O O B I O B I O
"Then , we use a global transitivity constraint on the graph to learn the optimal set of edges , formulating the optimization problem as an Integer Linear Program .",O O O O O B I I O O O O O O B I I I O O O B I O O B I I O
"The algorithm is applied in a setting where , given a target concept , the algorithm learns on the ﬂy all entailment rules between predicates that co - occur with this concept .",O O O O O O O O O O O B I O O O O O O O O B I O O O O O O O O O O
Results show that our global algorithm improves performance over baseline algorithms by more than 10 % .,O O O O B I O O O B I O O O O O O
"Motivated by the task of semantic parsing , we describe a transition system that generalizes standard transition - based dependency parsing techniques to generate a graph rather than a tree .",O O O O O B I O O O O B I O O B I I I I I I O O O B O O O B O
"Our system includes a cache with fixed size m , and we characterize the relationship between the parameter m and the class of graphs that can be produced through the graph - theoretic concept of tree decomposition .",O B O O B O B I I O O O O O O O O B I O O B I I O O O O O O B I I I O B I O
We find empirically that small cache sizes cover a high percentage of sentences in existing semantic corpora .,O O O O B I I O O O O O B O O B I O
"Despite the recent success of deep neural networks in natural language processing and other spheres of artificial intelligence , their interpretability remains a challenge .",O O O O O B I I O B I I O O O O B I O O B O O O O
We analyze the representations learned by neural machine translation ( NMT ) models at various levels of granularity and evaluate their quality through relevant extrinsic properties .,O O O B O O B I I O B O B O O B I I O O O O O O B I O
"In particular , we seek answers to the following questions : ( i ) How accurately is word structure captured within the learned representations , which is an important aspect in translating morphologically rich languages ? ( ii ) Do the representations capture long - range dependencies , and effectively handle syntactically divergent languages ? ( iii ) Do the representations capture lexical semantics ? We conduct a thorough investigation along several parameters : ( i ) Which layers in the architecture capture each of these linguistic phenomena ; ( ii ) How does the choice of translation unit ( word , character , or subword unit ) impact the linguistic properties captured by the underlying representations ? ( iii ) Do the encoder and decoder learn differently and independently ? ( iv ) Do the representations learned by multilingual NMT models capture the same amount of linguistic information as their bilingual counterparts ? Our data - driven , quantitative evaluation illuminates important aspects in NMT models and their ability to capture various linguistic phenomena .",O O O O O O O O O O O O O O O O O B I O O O B I O O O O O O O B B I I O O O O O O B O B I I I O O O O B I I O O O O O O B O B I O O O O O O O O O O O O O O B O O B O O O O B I O O O O O O O O O B I O B O B O O B I O O O B I O O O O B O O O O O O B O B O O O O O O O O O O B I O B I I O O O O O B I O O B I O O B I I O O O O O O O B I O O O O O O B I O
"We show that deep NMT models trained in an end - to - end fashion , without being provided any direct supervision during the training process , learn a non - trivial amount of linguistic information .",O O O B I I B O O B I I I I O O O O O O B I O O B I O O O O O O O O B I O
"Notable findings include the following observations : ( i ) Word morphology and part - of - speech information are captured at the lower layers of the model ; ( ii ) In contrast , lexical semantics or non - local syntactic and semantic dependencies are better represented at the higher layers of the model ; ( iii ) Representations learned using characters are more informed about word - morphology compared to those learned using subword units ; and ( iv ) Representations learned by multilingual models are richer compared to bilingual models .",O O O O O O O O O O B I O B I I I I I O O O O B I O O B O O O O O O O B I O O O O B I B I O O O O O B I O O B O O O O B I O B O O O O B I I O O O O O B I O O O O O B I O B I O O O O B I O
"The most widely adopted approaches for evaluation of summary content follow some protocol for comparing a summary with gold - standard human summaries , which are traditionally called model summaries .",O O O O O O B O B I O O O O O O O O B I I B I O O O O O B I O
This evaluation paradigm falls short when human summaries are not available and becomes less accurate when only a single model is available .,O B I O O O B I O O O O O O O O O O O B O O O
We propose three novel evaluation techniques .,O O O O B I O
Two of them are model - free and do not rely on a gold standard for the assessment .,O O O O B I I O O O O O O B I O O O O
The third technique improves standard automatic evaluations by expanding the set of available model summaries with chosen system summaries .,O O O O O B I O O O O O O B O O O O O O
We show that quantifying the similarity between the source text and its summary with appropriately chosen measures produces summary scores which replicate human assessments accurately .,O O O O O O O O O O O O O O O O O O O O O O O O O O
We also explore ways of increasing evaluation quality when only one human model summary is available as a gold standard .,O O O O O O B I O O O B I I O O O O B I O
"We introduce pseudomodels , which are system summaries deemed to contain good content according to automatic evaluation .",O O B O O O B I O O O O O O O B I O
Combining the pseudomodels with the single human model to form the gold - standard leads to higher correlations with human judgments compared to using only the one available model .,O O B O O B I I O O O B I I O O O B O O O O O O O O O O B O
"Finally , we explore the feasibility of another measure — similarity between a system summary and the pool of all other system summaries for the same input .",O O O O O O O O B I I O O O O O O O O O O O O O O O O O
"This method of comparison with the consensus of systems produces impressively accurate rankings of system summaries , achieving correlation with human rankings above 0.9 .",O O O O O O O O O O O O O O O O O O B O O O O O O
"In this article , an integrated model is derived that jointly identifies and aligns bilingual named entities ( NEs ) between Chinese and English .",O O O O O O O O O O O O O O B B I O B O O O O O O
"The model is motivated by the following observations : ( 1 ) whether an NE is translated semantically or phonetically depends greatly on its entity type , ( 2 ) entities within an aligned pair should share the same type , and ( 3 ) the initially detected NEs can act as anchors and provide further information while selecting NE candidates .",O B O O O O O O O O O O O O B O O B O B O O O O B I O O O O B O O B I O O O O O O O O O O O O O B O O O O O O O O O O B O O
"Based on these observations , this article proposes a translation mode ratio feature ( defined as the proportion of NE internal tokens that are semantically translated ) , enforces an entity type consistency constraint , and utilizes additional new NE likelihoods ( based on the initially detected NE anchors ) .",O O O O O O O O O O O O O O O O O O O B O B O O B I O O O O B I B I O O O O O B B O O O O O O B O O O
Experiments show that this novel method significantly outperforms the baseline .,O O O O O O O O O B O
"The type - insensitive F - score of identified NE pairs increases from 78.4 % to 88.0 % ( 12.2 % relative improvement ) in our Chinese – English NE alignment task , and the type - sensitive F - score increases from 68.4 % to 83.0 % ( 21.3 % relative improvement ) .",O B I I B I I O O B O O O O O O O O O O O O O O O O O O O B I I O O O B I I B I I O O O O O O O O O O O O O O
"Furthermore , the proposed model demonstrates its robustness when it is tested across different domains .",O O O O O O O O O O O O O O O O
"Finally , when semi - supervised learning is conducted to train the adopted English NE recognition model , the proposed model also significantly boosts the English NE recognition type - sensitive F - score .",O O O B I I I O O O O O O O B I I O O O O O O O O O B I B I I B I I O
Entailment rules between predicates are fundamental to many semantic - inference applications .,B I O B O O O O B O B O O
"Consequently , learning such rules has been an active field of research in recent years .",O O B O O O O O O O O O O O O O
"Methods for learning entailment rules between predicates that take into account dependencies between different rules ( e.g. , entailment is a transitive relation ) have been shown to improve rule quality , but suffer from scalability issues , that is , the number of predicates handled is often quite small .",O O B I O O B O O O O B O O O O O O O O O B I O O O O O O O O O O O O O O O O O O O O O B O O O O O O
"In this article , we present methods for learning transitive graphs that contain tens of thousands of nodes , where nodes represent predicates and edges correspond to entailment rules ( termed entailment graphs ) .",O O O O O O O O B I I O O O O O O O O O O O B O O O O B I O O B I O O
Our methods are able to scale to a large number of predicates by exploiting structural properties of entailment graphs such as the fact that they exhibit a “ tree - like ” property .,O O O O O O O O O O O B O O O O O B I O O O O O O O O O O O O O O O
"We apply our methods on two data sets and demonstrate that our methods find high - quality solutions faster than methods proposed in the past , and moreover our methods for the first time scale to large graphs containing 20,000 nodes and more than 100,000 edges .",O O O O O O B I O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O
This article investigates the effects of different degrees of contextual granularity on language model performance .,O O O O O O O O O B I O B I O O
"It presents a new language model that combines clustering and half - contextualization , a novel representation of contexts .",O O O O B I O O B O B I I O O O O O B O
Half - contextualization is based on the half - context hypothesis that states that the distributional characteristics of a word or bigram are best represented by treating its context distribution to the left and right separately and that only directionally relevant distributional information should be used .,B I I O O O O B I I I O O O O B I O O O O B O O O O O O B I O O O O O O O O O B I B I O O O O
Clustering is achieved using a new clustering algorithm for class - based language models that compares favorably to the exchange algorithm .,B O O O O O B B O B I I B I O O O O O B I O
"When interpolated with a Kneser - Ney model , half - context models are shown to have better perplexity than commonly used interpolated n - gram models and traditional class - based approaches .",O O O O B I I I O B I I I O O O O O B O O O O B I I B O O B I I I O
"A novel , fine - grained , context - specific analysis highlights those contexts in which the model performs well and those which are better treated by existing non - class - based models .",O O O O O O O O O O O O O O O O O B O O O O O O O O O O B I I I I B O
"Newly coined words pose problems for natural language processing systems because they are not in a system 's lexicon , and therefore no lexical information is available for such words .",B I I O O O B I I I O O O O O O O O B O O O O B I O O O O O O
"A common way to form new words is lexical blending , as in cosmeceutical , a blend of cosmetic and pharmaceutical .",O O O O O O O O B I O O O O O O O O O O O O
We propose a statistical model for inferring a blend 's source words drawing on observed linguistic properties of blends ; these properties are largely based on the recognizability of the source words in a blend .,O O O B I O B O B O B I O O O B I O O O O O O O O O O B O O B I O O B O
"We annotate a set of 1,186 recently coined expressions which includes 515 blends , and evaluate our methods on a 324 - item subset .",O B O O O O O B I O O O O O O O O O O O O O O O O
"In this first study of novel blends we achieve an accuracy of 40 % on the task of inferring a blend 's source words , which corresponds to a reduction in error rate of 39 % over an informed baseline .",O O O O O O O O O O O O O O O O O O B O B O B I O O O O O O O B I O O O O O B I O
We also give preliminary results showing that our features for source word identification can be used to distinguish blends from other kinds of novel words .,O O O O O O O O O O B I I O O O O O B O O O O B I O
"Nominal compounds such as red wine and nut case display a continuum of compositionality , with varying contributions from the components of the compound to its semantics .",B I O O O O O O O O O B O I O O O O O O O O O O O O B O
"This article proposes a framework for compound compositionality prediction using distributional semantic models , evaluating to what extent they capture idiomaticity compared to human judgments .",O O O O O O B I I O B I I O O O O O O O O O O O O O
"For evaluation , we introduce data sets containing human judgments in three languages : English , French , and Portuguese .",O O O O O B I O O O O O O O O O O O O O O
"The results obtained reveal a high agreement between the models and human predictions , suggesting that they are able to incorporate information about idiomaticity .",O O O O O O O O O I O O O O O O O O O O O O O B O
"We also present an in - depth evaluation of various factors that can affect prediction , such as model and corpus parameters and compositionality operations .",O O O O O O O O O O O O O O O O O O O O B I O B I O
"General crosslingual analyses reveal the impact of morphological variation and corpus size in the ability of the model to predict compositionality , and of a uniform combination of the components for best results .",O B I O O O O B I O B O O O O O O B O O B O O O O B I O O O O O O O
In this article we discuss several metrics of coherence defined using centering theory and investigate the usefulness of such metrics for information ordering in automatic text generation .,O O O O O O B I I O O B I O O O O O O B O O O O B I I O
We estimate empirically which is the most promising metric and how useful this metric is using a general methodology applied on several corpora .,O O O O O O O O B O O O O B O O O O O O O O B O
Our main result is that the simplest metric ( which relies exclusively on NOCB transitions ) sets a robust baseline that cannot be outperformed by other metrics which make use of additional centering based features .,O O O O O O O O O O O O O B I O O O O B O O O O O O B O O O O O B I I O
"Event processing is an active area of research in the Natural Language Processing community , but resources and automatic systems developed so far have mainly addressed contemporary texts .",B I O O O O O O O O B I I O O O O O O O O O O O O O O O O
"However , the recognition and elaboration of events is a crucial step when dealing with historical texts Particularly in the current era of massive digitization of historical sources : Research in this domain can lead to the development of methodologies and tools that can assist historians in enhancing their work , while having an impact also on the field of Natural Language Processing .",O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O B I I O
Our work aims at shedding light on the complex concept of events when dealing with historical texts .,O O O O O O O O O O O O O O O O O O
"More specifically , we introduce new annotation guidelines for event mentions and types , categorized into 22 classes .",O O O O O O B I O O O O O O O O O O O
"Then , we annotate a historical corpus accordingly , and compare two approaches for automatic event detection and classification following this novel scheme .",O O O B O O B O O O O O O O B I I O B O O O O O
We believe that this work can foster research in a field of inquiry as yet underestimated in the area of Temporal Information Processing .,O O O O O O O O O O O O O O O O O O O O B I I O
"To this end , we release new annotation guidelines , a corpus , and new models for automatic annotation .",O O O O O O O B I O O B O O O B I I I O
Probabilistic finite - state automata are a formalism that is widely used in many problems of automatic speech recognition and natural language processing .,B I I I I O O B O O O O O O O O B I I O B I I O
"Probabilistic finite - state automata are closely related to other finite - state models as weighted finite - state automata , word lattices , and hidden Markov models .",B I I I I O O O O O B I I I O B I I I I O B I O O B I I O
"Therefore , they share many similar properties and problems .",O O O O O O O O O O
Entropy measures of finite - state models have been investigated in the past in order to study the information capacity of these models .,B I O B I I I O O O O O O O O O O O B I O O O O
The derivational entropy quantifies the uncertainty that the model has about the probability distribution it represents .,O B I O O B O O O O O O B I O O O
The derivational entropy in a finite - state automaton is computed from the probability that is accumulated in all of its individual state sequences .,O B I O O B I I I O O O O O O O O O O O O B I I O
The computation of the entropy from a weighted finite - state automaton requires a normalized model .,O O O O B O O B I I I I O O B I O
"This article studies an efficient computation of the derivational entropy of left - to - right probabilistic finite - state automata , and it introduces an efficient algorithm for normalizing weighted finite - state automata .",O O O O O O O O B I O O O O O O B I I I I O O O O O O B O O B I I I I O
The efficient computation of the derivational entropy is also extended to continuous hidden Markov models .,O O O O O B I O O O O B I I I O
This article describes the application of computational models of spatial prepositions to visually situated dialog systems .,O O O O O O B I O B I O B I I I O
"In these dialogs , spatial prepositions are important because people often use them to refer to entities in the visual context of a dialog .",O O O O B I O O O O O O O O O O B O O O O O O O O
"We first describe a generic architecture for a visually situated dialog system and highlight the interactions between the spatial cognition module , which provides the interface to the models of prepositional semantics , and the other components in the architecture .",O O O O B I O O B I I I O O O O O O B I I O O O O B O O B O B I O O O O O O O B O
"Following this , we present two new computational models of topological and projective spatial prepositions .",O O O O O O O B I O B O B I I O
The main novelty within these models is the fact that they account for the contextual effect which other distractor objects in a visual scene can have on the region described by a given preposition .,O O O O O B O O O O O O O O B I O O B I O O O O O O O O O O O O O B O
"We next present psycholinguistic tests evaluating our approach to distractor interference on prepositional semantics , and illustrate how these models are used for both interpretation and generation of prepositional expressions .",O O O B I O O O O B I O B I O O O O O B O O O O O O B O B I O
"Most of the world languages are resource - poor for statistical machine translation still , many of them are actually related to some resource - rich language .",O O O O O O B I I O B I I O O O O O O O B O O B I I I O
"Thus , we propose three novel , language - independent approaches to source language adaptation for resource - poor statistical machine translation .",O O O O O O O B I I I O B I I O B I I I I I O
"Specifically , we build improved statistical machine translation models from a resource - poor language POOR into a target language TGT by adapting and using a large bitext for a related resource - rich language RICH and the same target language TGT .",O O O O O B I I I O O B I I I B O O B I I O B O O O B I O O B I I I I I O O O B I B O
We assume a small POOR – TGT bitext from which we learn word - level and phrase - level paraphrases and cross - lingual morphological variants between the resource - rich and the resource - poor language .,O O O B I I I I O O O O O O O O O O O O O B I I I I O O B I I O O B I I I O
Our work is of importance for resource - poor machine translation because it can provide a useful guideline for people building machine translation systems for resource - poor languages .,O O O O O O B I I I I O O O O O O B O O O B I I O B I I I O
Our experiments for Indonesian / Malay – English translation show that using the large adapted resource - rich bitext yields 7.26 BLEU points of improvement over the unadapted one and 3.09 BLEU points over the original small bitext .,O O O O O O O O O O O O O B I I I I I O O B O O O O O O O O O B O O O O O O O
"Moreover , combining the small POOR – TGT bitext with the adapted bitext outperforms the corresponding combinations with the unadapted bitext by 1.93–3.25 BLEU points .",O O O O B I I I I O O B I O O O O O O B I O O B O O
We also demonstrate the applicability of our approaches to other languages and domains .,O O O O O O O O O O O O B O
"This article describes a framework for incorporating referential semantic information from a world model or ontology directly into a probabilistic language model of the sort commonly used in speech recognition , where it can be probabilistically weighted together with phonological and syntactic factors as an integral part of the decoding process .",O O O O B O O B I I O O B I O B O O O B I I O O O O O O B I O O O O O B I O O B O B I O O O O O O B I O
"Introducing world model referents into the decoding search greatly increases the search space , but by using a single integrated phonological , syntactic , and referential semantic language model , the decoder is able to incrementally prune this search based on probabilities associated with these combined contexts .",O B I I O O B I O O O B I O O O O O O O B O B O O B I I I O O B O O O O B O O O O O O O O O O O
"The result is a single unified referential semantic probability model which brings several kinds of context to bear in speech decoding , and performs accurate recognition in real time on large domains in the absence of example in domain training sentences .",O O O O O O B I I I O O O O O O O O O B I O O O O B O O O O O O O O O O O B I I I O
Many approaches to automatic sentiment analysis begin with a large lexicon of words marked with their prior polarity ( also called semantic orientation ) .,O O O B I I O O O O B O O O O O B I O O O B I O O
"However , the contextual polarity of the phrase in which a particular instance of a word appears may be quite different from the word 's prior polarity .",O O O B I O O O O O O O B O O O O O O O O O O O O B I O
"Positive words are used in phrases expressing negative sentiments , or vice versa .",O O O O O O O O O O O O O O
"Also , quite often words that are positive or negative out of context are neutral in context , meaning they are not even being used to express a sentiment .",O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O
"The goal of this work is to automatically distinguish between prior and contextual polarity , with a focus on understanding which features are important for this task .",O O O O O O O O O O O O B I O O O O O O O B O O O O B O
"Because an important aspect of the problem is identifying when polar terms are being used in neutral contexts , features for distinguishing between neutral and polar instances are evaluated , as well as features for distinguishing between positive and negative contextual polarity .",O O O O O O O O O O B I O O O O O O O B O O O O O B I O O O O O O B O O O O O B I I O
The evaluation includes assessing the performance of features across multiple machine learning algorithms .,O O O O O O O B O O B I I O
"For all learning algorithms except one , the combination of all features together gives the best performance .",O O B I O O O O O O O B O O O O O O
Another facet of the evaluation considers how the presence of neutral instances affects the performance of features for distinguishing between positive and negative polarity .,O O O O O O O O O O B I O O O O B O O O O O B I O
"These experiments show that the presence of neutral instances greatly degrades the performance of these features , and that perhaps the best way to improve performance across all polarity classes is to improve the system 's ability to identify when an instance is neutral .",O O O O O O O B I O B O O O O B O O O O O O O O O O O O B I O O O O O O O O O O O B O O O
"Knowing the degree of semantic contrast between words has widespread application in natural language processing , including machine translation , information retrieval , and dialogue systems .",O O O O B O O O O O O O B I I O O B I O B I O O B I O
"Manually created lexicons focus on opposites , such as hot and cold .",O O B O O O O O O O O O O
"Opposites are of many kinds such as antipodals , complementaries , and gradable .",O O O O O O O B O B O O B O
"Existing lexicons often do not classify opposites into the different kinds , however .",O B O O O O O O O O O O O O
"They also do not explicitly list word pairs that are not opposites but yet have some degree of contrast in meaning , such as warm and cold or tropical and freezing .",O O O O O O B I O O O O O O O O O O O O O O O O O O O O O O O O
"We propose an automatic method to identify contrasting word pairs that is based on the hypothesis that if a pair of words , A and B , are contrasting , then there is a pair of opposites , C and D , such that A and C are strongly related and B and D are strongly related .",O O O O O O O O B I O O O O O O O O O B I I O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O
"( For example , there exists the pair of opposites hot and cold such that tropical is related to hot , and freezing is related to cold .",O O O O O O O O O O O O O O O O O O O O O O O O O O O O
) We will call this the contrast hypothesis .,O O O O O O O O O
We begin with a large crowdsourcing experiment to determine the amount of human agreement on the concept of oppositeness and its different kinds .,O O O O B B I O O O O O O O O O O O O O O O O O
"In the process , we flesh out key features of different kinds of opposites .",O O O O O O O O O O O O O O O
"We then present an automatic and empirical measure of lexical contrast that relies on the contrast hypothesis , corpus statistics , and the structure of a Roget - like thesaurus .",O O O O O O B I O B I O O O O O O O B O O O O O O O B I I I O
"We show how , using four different data sets , we evaluated our approach on two different tasks , solving “ most contrasting word ” questions and distinguishing synonyms from opposites .",O O O O O O O B I O O B O O O O O B O O O O O O O O O O B O O O
The results are analyzed across four parts of speech and across five different kinds of opposites .,O O O O O O B I I O O O O O O O O
"We show that the proposed measure of lexical contrast obtains high precision and large coverage , outperforming existing methods .",O O O O O O O B I O O O O O O O O O O O
We present online learning techniques for statistical machine translation ( SMT ) .,O O O O O O B I I O B O O
"The availability of large training data sets that grow constantly over time is becoming more and more frequent in the field of SMT — for example , in the context of translation agencies or the daily translation of government proceedings .",O O O O B I I O O O O O O O O O O O O O O O B O O O O O O O O B I O O O O O O O O
"When new knowledge is to be incorporated in the SMT models , the use of batch learning techniques require very time - consuming estimation processes over the whole training set that may take days or weeks to be executed .",O O O O O O O O O B I O O O O B I O O O O O O O O O O O B I O O O O O O O O O O
"By means of the application of online learning , new training samples can be processed individually in real time .",O O O O O O O O O O B I O O O O O O O O
"For this purpose , we define a state - of - the - art SMT model composed of a set of submodels , as well as a set of incremental update rules for each of these submodels .",O O O O O O O B I I I I I I B I O O O O O B O O O O O O O B I O O O O O B O
"To test our techniques , we have studied two well - known SMT applications that can be used in translation agencies : post - editing and interactive machine translation .",O O O O O O O O O O O O B O O O O O O B I O B I I O B I I O
"In both scenarios , the SMT system collaborates with the user to generate high - quality translations .",O O O O O B I O O O O O O O O O B O
These user - validated translations can be used to extend the SMT models by means of online learning .,O B I I I O O O O O O B I O O O O O O
Empirical results in the two scenarios under consideration show the great impact of frequent updates in the system performance .,B I O O O O O O O O O O O O O O O O O O
"The time cost of such updates was also measured , comparing the efficiency of a batch learning SMT system with that of an online learning system , showing that online learning is able to work in real time whereas the time cost of batch retraining soon becomes infeasible .",O O O O O O O O O O O O O O O B I I I O O O O O O O O O O O O O O O O O O O O O O O O B I O O O O
Empirical results also showed that the performance of online learning is comparable to that of batch learning .,B I O O O O O O O O O O O O O B I O
"Moreover , the proposed techniques were able to learn from previously estimated models or from scratch .",O O O O O O O O B O O O O O O O O
We also propose two new measures to predict the effectiveness of online learning in SMT tasks .,O O O O O O O O O O O O O O B I O
The translation system with online learning capabilities presented here is implemented in the open - source Thot toolkit for SMT .,O B I O O O O O O O O O O O O O O O O B O
This article presents a probabilistic hierarchical clustering model for morphological segmentation .,O O O O B I I I O B I O
"In contrast to existing approaches to morphology learning , our method allows learning hierarchical organization of word morphology as a collection of tree structured paradigms .",O O O O O O B I O O O O O B I I I I O O O O B I I O
The model is fully unsupervised and based on the hierarchical Dirichlet process .,O B O B I O O O O B I I O
Tree hierarchies are learned along with the corresponding morphological paradigms simultaneously .,B I O O O O O O B I O O
Our model is evaluated on Morpho Challenge and shows competitive performance when compared to state - of - the - art unsupervised morphological segmentation systems .,O O O O O B I O O O O O O O B I I I I I I B I I I O
"Although we apply this model for morphological segmentation , the model itself can also be used for hierarchical clustering of other types of data .",O O O O O O B I O O B O O O O O O B I O O O O O O
"From the perspective of structural linguistics , we explore paradigmatic and syntagmatic lexical relations for Chinese POS tagging , an important and challenging task for Chinese language processing .",O O O O B I O O O B O B I I O O B I O O O O O O O O B I O
Paradigmatic lexical relations are explicitly captured by word clustering on large - scale unlabeled data and are used to design new features to enhance a discriminative tagger .,B I I O O O O B I O B I I I I O O O O O O O O O O B I O
"Syntagmatic lexical relations are implicitly captured by syntactic parsing in the constituency formalism , and are utilized via system combination .",B I I O O O O B I O O B I O O O O O O O O
Experiments on the Penn Chinese Treebank demonstrate the importance of both paradigmatic and syntagmatic relations .,O O O B I I O O O O O B I I I O
"Our linguistically motivated , hybrid approaches yield a relative error reduction of 18 % in total over state - of - the - art baselines .",O B O O O O O O O O O O O O O O O O O O O O O O O O
"Despite the effectiveness to boost accuracy , computationally expensive parsers make hybrid systems inappropriate for many realistic NLP applications .",O O O O O O O B I I O O O O O O O B O O
"In this article , we are also concerned with improving tagging efficiency at test time .",O O O O O O O O O O B I O B I O
"In particular , we explore unlabeled data to transfer the predictive power of hybrid models to simple sequence models .",O O O O O B I O O O O O O O O O B I I O
"Specifically , hybrid systems are utilized to create large - scale pseudo training data for cheap models .",O O B I O O O O O O O O O O O O O O
"Experimental results illustrate that the re - compiled models not only achieve high accuracy with respect to per token classification , but also serve as a front - end to a parser well .",O O O O O O O O O O O O O O O O O O O O O O O O O O B I I O O O O O
The article describes a pilot implementation of a grammar containing different types of locative PPs .,O O O O O O O O B O O O O B I O
"In particular , we investigate the distinction between static and directional locatives , and between different types of directional locatives .",O O O O O O O O B O B I O O O O O O B I O
Locatives may act as modifiers as well as referring expressions depending on the syntactic context .,B O O O B O O O B I O O O B I O
We handle this with a single lexical entry .,O O O O O O B I O
"The implementation is of Norwegian locatives , but English locatives are both discussed and compared to Norwegian locatives .",O O O O O B O O O B O O O O O O O B O
"The semantic analysis is based on a proposal by Markus Kracht ( 2OO2 ) , and we show how this analysis can be incorporated into Minimal Recursion Semantics ( MRS ) ( Copestake et al .",O B I O O O O O O O O O O O O O O O O O O O O O O B I I O B O O O O O O
2OO5 ) .,O O O
"We discuss how the resulting system may be applied in a transfer based machine translation system , and how we can map from a shallow MRS representation to a deeper semantic representation .",O O O O O O O O O O O B I I I I O O O O O B O O O B I O O B B I O
"This article considers the problem of correcting errors made by English as a Second Language writers from a machine learning perspective , and addresses an important issue of developing an appropriate training paradigm for the task , one that accounts for error patterns of non - native writers using minimal supervision .",O O O O O O B I O O B O O B I O O O B I I O O O O O O O O O O B I O O O O O O O O B I O O O O O O B I O
Existing training approaches present a trade - off between large amounts of cheap data offered by the native - trained models and additional knowledge of learner error patterns provided by the more expensive method of training on annotated learner data .,O B I O O O O O O B I I I I O O O B I I I O O B I I I I O O O O O B I I O B O B O
We propose a novel training approach that draws on the strengths offered by the two standard training paradigms — of training either on native or on annotated learner data — and that outperforms both of these standard methods .,O O O O B I O O O O O O O O O O B I O O B O O O O O B I I O O O B O O O B I O
"Using the key observation that parameters relating to error regularities exhibited by non - native writers are relatively simple , we develop models that can incorporate knowledge about error regularities based on a small annotated sample but that are otherwise trained on native English data .",O O O O O B O O O O O O O O O O O O O O O O B O O O B O O O O O O O B O O O O O B O B I I O
The key contribution of this article is the introduction and analysis of two methods for adapting the learned models to error patterns of non - native writers ; one method that applies to generative classifiers and a second that applies to discriminative classifiers .,O O O O O O O O O O O O O B O O O B I O O O O O O O O O O B O O O B I O O O O O O B I O
Both methods demonstrated state - of - the - art performance in several text correction competitions .,O B O B I I I I I I I O O B I O O
"In particular , the Illinois system that implements these methods ranked at the top in two recent CoNLL shared tasks on error correction We conduct further evaluation of the proposed approaches studying the effect of using error data from speakers of the same native language , languages that are closely related linguistically , and unrelated languages .",O O O O B I O O O B O O O O O O O B O O O I I O O O B O O O B O O O O O B I O B O O O B I O B O O O O B O O B I O
Finding the right representations for words is critical for building accurate NLP systems when domain - specific labeled data for the task is scarce .,O O O O O B O O O O O B I O O O O B B O O B O O O
"This article investigates novel techniques for extracting features from n - gram models , Hidden Markov Models , and other statistical language models , including a novel Partial Lattice Markov Random Field model .",O O O O O O B I O B I I O O B I I O O O B I I O O O O O B I I I I O
"Experiments on part - of - speech tagging and information extraction , among other tasks , indicate that features taken from statistical language models , in combination with more traditional features , outperform traditional representations alone , and that graphical model representations outperform n - gram models , especially on sparse and polysemous words .",B O O O O O B I O B I O O O O O O O B O O B I I O O O O O B I O O O B O O O O B I I O B I I I O O O B I I I O
Named entity recognition systems achieve remarkable performance on domains such as English news .,B I I O O O O O O O O O O O
"It is natural to ask : What are these models actually learning to achieve this ? Are they merely memorizing the names themselves ? Or are they capable of interpreting the text and inferring the correct entity type from the linguistic context ? We examine these questions by contrasting the performance of several variants of architectures for named entity recognition , with some provided only representations of the context as features .",O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O B I O O O O O O O O O O O O O O O B I I O O O O O O O O O O O O
We experiment with GloVe - based BiLSTM - CRF as well as BERT .,O O O B I I B I I O O O B O
"We find that context does influence predictions , but the main factor driving high performance is learning the named tokens themselves .",O O O O O O O O O O O O O O O O O O B I O O
"Furthermore , we find that BERT is not always better at recognizing predictive contexts compared to a BiLSTM - CRF model .",O O O O O B O O O O O O B I O O O B I I I O
We enlist human annotators to evaluate the feasibility of inferring entity types from context alone and find that humans are also mostly unable to infer entity types for the majority of examples on which the context - only system made errors .,O O O B O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O B I I I O O O
"However , there is room for improvement : A system should be able to recognize any named entity in a predictive context correctly and our experiments indicate that current systems may be improved by such capability .",O O O O O O O O O O O O O O O O B I O O B I O O O O O O O O O O O O O O O
"Our human study also revealed that systems and humans do not always learn the same contextual clues , and context - only systems are sometimes correct even when humans fail to recognize the entity type from the context .",O O O O O O O O O O O O O O O O O O O B I I I O O O O O O O O O O O O O O O O
"Finally , we find that one issue contributing to model errors is the use of “ entangled ” representations that encode both contextual and local token information into a single vector , which can obscure clues .",O O O O O O O O O B I O O O O O B O O O B O O O B I I O O O B O O O O O O
"Our results suggest that designing models that explicitly operate over representations of local inputs and context , respectively , may in some cases improve performance .",O O O O O O O O O O O O O O O O O O O O O O O O O O
"In light of these and related findings , we highlight directions for future work .",O O O O O O O O O O O O O O O
The weak equivalence of Combinatory Categorial Grammar ( CCG ) and Tree - Adjoining Grammar ( TAG ) is a central result of the literature on mildly context - sensitive grammar formalisms .,O O O O B I I O B O O B O B I O B O O O O O O O O O O O O B I I O
"However , the categorial formalism for which this equivalence has been established differs significantly from the versions of CCG that are in use today .",O O O B I O O O O O O O O O O O O O B O O O O O O
"In particular , it allows restriction of combinatory rules on a per grammar basis , whereas modern CCG assumes a universal set of rules , isolating all cross - linguistic variation in the lexicon .",O O O O O O O B I O O O B I O O O B O O O O O O O O O O O B I O O B O
In this article we investigate the formal significance of this difference .,O O O O O O O O O O O O
Our main result is that lexicalized versions of the classical CCG formalism are strictly less powerful than TAG .,O O O O O B O O O O B O O O O O O B O
What is here called controlled natural language ( CNL ) has traditionally been given many different names .,O O O O B I I O B O O O O O O O O O
"Especially during the last four decades , a wide variety of such languages have been designed .",O O O O O O O O O O O O B O O O O
"They are applied to improve communication among humans , to improve translation , or to provide natural and intuitive representations for formal notations .",O O O O O B O O O O O B O O O O B O O O O O B O
"Despite the apparent differences , it seems sensible to put all these languages under the same umbrella .",O O O O O O O O O O O O B O O O O O
"To bring order to the variety of languages , a general classification scheme is presented here .",O O O O O O O B O O O B I O O O O
"A comprehensive survey of existing English - based CNLs is given , listing and describing 100 languages from 1930 until today .",O O O O O B I I I O O O O O O O B O O O O O
Classification of these languages reveals that they form a single scattered cloud filling the conceptual space between natural languages such as English on the one end and formal languages such as propositional logic on the other .,B O O B O O O O O O O O O O O O O B I O O B O O O O O B I O O B I O O O O
"The goal of this article is to provide a common terminology and a common model for CNL , to contribute to the understanding of their general nature , to provide a starting point for researchers interested in the area , and to help developers to make design decisions .",O O O O O O O O O O B O O O B O B O O O O O B O O O O O O O O O O O O O O O O O O O O O O O O O O
This work is focused on in machine learning for coreference resolution .,O O O O O O B I O B I O
Coreference resolution is a natural language processing task that consists of determining the expressions in a discourse that refer to the same entity .,B I O O B I I I O O O O O O O O B O O O O O O O
"The main contributions of this article are ( i ) a new approach to coreference resolution based on constraint satisfaction , using a hypergraph to represent the problem and solving it by relaxation labeling ; and ( ii ) research towards improving coreference resolution performance using world knowledge extracted from Wikipedia .",O O O O O O O O O O O O O O B I O O B I O O O B O O O O O O O O B I O O O O O O O O B I I O B I O O O O
"The developed approach is able to use an entity - mention classification model with more expressiveness than the pair - based ones , and overcome the weaknesses of previous approaches in the state of the art such as linking contradictions , classifications without context , and lack of information evaluating pairs .",O O O O O O O O B I I I I O O O O O B I I O O O O O O O O O O O B I I I O O B I O B O B O O O O O O O O
"Furthermore , the approach allows the incorporation of new information by adding constraints , and research has been done in order to use world knowledge to improve performances .",O O O O O O O O O O O O O O O O O O O O O O O O O O O O O
"RelaxCor , the implementation of the approach , achieved results at the state - of - the - art level , and participated in international competitions : SemEval-2010 and CoNLL-2011 .",O O O O O O O O O O O O B I I I I I I O O O O O O O O O O O O
RelaxCor achieved second place in CoNLL-2011 .,O O O O O O O
"Microblogs such as Twitter , Facebook , and Sina Weibo ( China 's equivalent of Twitter ) are a remarkable linguistic resource .",B O O O O O O O O O O O O O O O O O O O B O O
"In contrast to content from edited genres such as newswire , microblogs contain discussions of virtually every topic by numerous individuals in different languages and dialects and in different styles .",O O O O O O O O O B O B O O O O O O O O O O O O O B O O O O O
"In this work , we show that some microblog users post “ self - translated ” messages targeting audiences who speak different languages , either by writing the same message in multiple languages or by retweeting translations of their original posts in a second language .",O O O O O O O O B O O B I I I I O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O
We introduce a method for finding and extracting this naturally occurring parallel data .,O O O O O O O O O B I I I O
"Identifying the parallel content requires solving an alignment problem , and we give an optimally efficient dynamic programming algorithm for this .",O O O O O O O B I O O O O O O O B I I O O O
"Using our method , we extract nearly 3 M Chinese – English parallel segments from Sina Weibo using a targeted crawl of Weibo users who post in multiple languages .",O O O O O O O O O O O O B I O O O O O O O O O O O O O O O O
"Additionally , from a random sample of Twitter , we obtain substantial amounts of parallel data in multiple language pairs .",O O O O O O O O O O O O O O B I O O B I O
Evaluation is performed by assessing the accuracy of our extraction approach relative to a manual annotation as well as in terms of utility as training data for a Chinese – English machine translation system .,O O O O O O O O O O O O O O B I O O O O O O O O B I O O O O O B I I O
"Relative to traditional parallel data resources , the automatically extracted parallel data yield substantial translation quality improvements in translating microblog text and modest improvements in translating edited news content .",O O O B I I O O O O B I O O B O O O O B O O O O O O O O O O
Word sense disambiguation and the related field of automated word sense induction traditionally assume that the occurrences of a lemma can be partitioned into senses .,B I I O O O O O B I I I O O O O O O O B O O O O O O
But this seems to be a much easier task for some lemmas than others .,O O O O O O O O O O O B O O O
"Our work builds on recent work that proposes describing word meaning in a graded fashion rather than through a strict partition into senses in this article we argue that not all lemmas may need the more complex graded analysis , depending on their partitionability .",O O O O O O O O O O O O O O O O O O O B I O B O O O O O O O O B O O O O O O O O O O O B O
"Although there is plenty of evidence from previous studies and from the linguistics literature that there is a spectrum of partitionability of word meanings , this is the first attempt to measure the phenomenon and to couple the machine learning literature on clusterability with word usage data used in computational linguistics .",O O O O O O O O O O O O O O O O O O B I I O O O O O O O O O O O O O O O O O B I I O B O O O O O O B I O
"We propose to operationalize partitionability as clusterability , a measure of how easy the occurrences of a lemma are to cluster .",O O O B I O B O O O O O O O O O O B O O B O
"We test two ways of measuring clusterability : ( 1 ) existing measures from the machine learning literature that aim to measure the goodness of optimal k - means clusterings , and ( 2 ) the idea that if a lemma is more clusterable , two clusterings based on two different “ views ” of the same data points will be more congruent .",O O O O O O B O O O O O O O O B I I O O O O O B I I I I I I O O O O O O O O O O B O O B O O B O O O O O O O O O O O O O O O B O
"The two views that we use are two different sets of manually constructed lexical substitutes for the target lemma , on the one hand monolingual paraphrases , and on the other hand translations .",O O O O O O O O O O O B I I I O O B I O O O O O B I O O O O O O B O
We apply automatic clustering to the manual annotations .,O O B I O O B I O
We use manual annotations because we want the representations of the instances that we cluster to be as informative and “ clean ” as possible .,O O B I O O O O O O O B O O B O O O B O O O O O O O
"We show that when we control for polysemy , our measures of clusterability tend to correlate with partitionability , in particular some of the type-(1 ) clusterability measures , and that these measures outperform a baseline that relies on the amount of overlap in a soft clustering .",O O O O O O O B O O O O B O O B O B O O O O O O B I I I O O O O O O O O O O O O O O O O O B I O
This article presents a comparative study of a subfield of morphology learning referred to as minimally supervised morphological segmentation .,O O O O O O O O O O B I O O O B I I I O
"In morphological segmentation , word forms are segmented into morphs , the surface forms of morphemes .",O B I O B I O B O B O O B I O B O
"In the minimally supervised data - driven learning setting , segmentation models are learned from a small number of manually annotated word forms and a large set of unannotated word forms .",O O B I I I I I I O B I O O O O O O O B I O O O O O O O B O O O
"In addition to providing a literature survey on published methods , we present an in - depth empirical comparison on three diverse model families , including a detailed error analysis .",O O O O O O O O O O O O O O O O O O O O O O B I O O O O B I O
"Based on the literature survey , we conclude that the existing methodology contains substantial work on generative morph lexicon - based approaches and methods based on discriminative boundary detection .",O O O O O O O O O O O O O O O O B I I O O O O O O O B I I O
"As for which approach has been more successful , both the previous work and the empirical evaluation presented here strongly imply that the current state of the art is yielded by the discriminative boundary detection methodology .",O O O O O O O O O O O O O O O B I O O O O O O O O O O O O O O O B I I I O
Authorship attribution deals with identifying the authors of anonymous texts .,B I O O O O O O O B O
"Traditionally , research in this field has focused on formal texts , such as essays and novels , but recently more attention has been given to texts generated by on - line users , such as e - mails and blogs .",O O O O O O O O O B I O O O O O O O O O O O O O O O B I O O O O O O O O O O O O O O
"Authorship attribution of such on - line texts is a more challenging task than traditional authorship attribution , because such texts tend to be short , and the number of candidate authors is often larger than in traditional settings .",O I O O O O B I O O O O B O O O B O O O B O O O O O O O O O O O O O O O O O O O
We address this challenge by using topic models to obtain author representations .,O O O O O O O B O O O B O
"In addition to exploring novel ways of applying two popular topic models to this task , we test our new model that projects authors and documents to two disjoint topic spaces .",O O O O O O O O O O B I O O O O O O O O O O O O O B O O B I I O
"Utilizing our model in authorship attribution yields state - of - the - art performance on several data sets , containing either formal texts written by a few authors or informal texts generated by tens to thousands of on - line users .",O O B O O B O O O O O O O O O O O B I O O O B I O O O O O O O B I O O O O O O O O O O
"We also present experimental results that demonstrate the applicability of topical author representations to two other problems : inferring the sentiment polarity of texts , and predicting the ratings that users would give to items such as movies .",O O O B O O O O O O B I I O O O O O B O B I O B O O B O B O O O O O O O O O O
"Spurious ambiguity is the phenomenon whereby distinct derivations in grammar may assign the same structural reading , resulting in redundancy in the parse search space and inefficiency in parsing .",B I O O O O O B O B O O O O B I O O O B O O B I I O B O B O
Understanding the problem depends on identifying the essential mathematical structure of derivations .,O O O O O O O O B I O B O
"This is trivial in the case of context free grammar , where the parse structures are ordered trees ; in the case of type logical categorial grammar , the parse structures are proof nets .",O O O O O O O B I I O O O B I O B I O O O O O B I I I O O B I O B I O
"However , with respect to multiplicatives , intrinsic proof nets have not yet been given for displacement calculus , and proof nets for additives , which have applications to polymorphism , are not easy to characterize .",O O O O O B O B I I O O O O O O B I O O B I O B O O O O O B O O O O O O O
In this context we approach here multiplicative - additive spurious ambiguity by means of the proof - theoretic technique of focalization .,O O O O O O B I I I I O O O O B I I I I I O
Research into representation learning models of lexical semantics usually utilizes some form of intrinsic evaluation to ensure that the learned representations reflect human semantic judgments .,O O B I I O B I O O O O O B I O O O O B I O B I I O
"Lexical semantic similarity estimation is a widely used evaluation method , but efforts have typically focused on pairwise judgments of words in isolation , or are limited to specific contexts and lexical stimuli .",B I I I O O O O O O O O O O O O O B I O O O O O O O O O O O O B I O
"There are limitations with these approaches that either do not provide any context for judgments , and thereby ignore ambiguity , or provide very specific sentential contexts that can not then be used to generate a larger lexical resource .",O O O O O O O O O O O O O O O O O O O O O O O O O B I O O O O O O O O O O B I O
"Furthermore , similarity between more than two items is not considered .",O O O O O O O O O O O O
"We provide a full description and analysis of our recently proposed methodology for large - scale data set construction that produces a semantic classification of a large sample of verbs in the first phase , as well as multi - way similarity judgments made within the resultant semantic classes in the second phase .",O O O O O O O O O O O O O B I I I I O O O O B I O O O O O O O O O O O O O O O O O B I O O O O B I O O O O O
The methodology uses a spatial multi - arrangement approach proposed in the field of cognitive neuroscience for capturing multi - way similarity judgments of visual stimuli .,O O O O B I I I I O O O O O B I O O O O O B I O B I O
We have adapted this method to handle polysemous linguistic stimuli and much larger samples than previous work .,O O O O O O O B I I O O O O O O O O
"We specifically target verbs , but the method can equally be applied to other parts of speech .",O O O O O O O O O O O O O O O O O O
We perform cluster analysis on the data from the first phase and demonstrate how this might be useful in the construction of a comprehensive verb resource .,O O B I O O O O O O O O O O O O O O O O O O O O O O O
We also analyze the semantic information captured by the second phase and discuss the potential of the spatially induced similarity judgments to better reflect human notions of word similarity .,O O O O B I O O O O O O O O O O O O O B I O O O O O O B I O
We demonstrate how the resultant data set can be used for fine - grained analyses and evaluation of representation learning models on the intrinsic tasks of semantic clustering and semantic similarity .,O O O O O O O O O O O O O O O O O O B I I O O O O O B I O B I O
"In particular , we find that stronger static word embedding methods still outperform lexical representations emerging from more recent pre - training methods , both on word - level similarity and clustering .",O O O O O O O O B I O O O B I O O O O B I I O O O O B I I I O B O
"Moreover , thanks to the data set ’s vast coverage , we are able to compare the benefits of specializing vector representations for a particular type of external knowledge by evaluating FrameNet- and VerbNet - retrofitted models on specific semantic domains such as “ Heat ” or “ Motion .",O O O O O O O O O O O O O O O O O O O O B I O O O O O O O O O B O B I I I O O B I O O O O O O O O O
We present a constituency parsing system for Modern Hebrew .,O O O B I O O O O O
The system is based on the PCFG - LA parsing method of Petrov et al .,O O O O O O B I I B O O O O O O
"2006 , which is extended in various ways in order to accommodate the specificities of Hebrew as a morphologically rich language with a small treebank .",O O O O O O O O O O O O O O O O O O B I I O O O B O
"We show that parsing performance can be enhanced by utilizing a language resource external to the treebank , specifically , a lexicon - based morphological analyzer .",O O O B O O O O O O O O O O O O B O O O O B I I B I O
"We present a computational model of interfacing the external lexicon and a treebank - based parser , also in the common case where the lexicon and the treebank follow different annotation schemes .",O O O B I O O O O B O O B I I I O O O O O O O O B O O B O O B I O
We show that Hebrew word - segmentation and constituency - parsing can be performed jointly using CKY lattice parsing .,O O O O B I I O B I I O O O O O B I I O
"Performing the tasks jointly is effective , and substantially outperforms a pipeline - based model .",O O O O O O O O O O O B I I I O
"We suggest modeling grammatical agreement in a constituency - based parser as a filter mechanism that is orthogonal to the grammar , and present a concrete implementation of the method .",O O O B I O O B I I I O O O O O O O O O O O O O O O O O O O O
"Although the constituency parser does not make many agreement mistakes to begin with , the filter mechanism is effective in fixing the agreement mistakes that the parser does make .",O O B I O O O O O O O O O O O O O O O O O O O O O O B O O O
"These contributions extend outside of the scope of Hebrew processing , and are of general applicability to the NLP community .",O O O O O O O O O B O O O O O O O O B O O
"Hebrew is a specific case of a morphologically rich language , and ideas presented in this work are useful also for processing other languages , including English .",O O O O O O O B I I O O O O O O O O O O O B O O O O O O
The lattice - based parsing methodology is useful in any case where the input is uncertain .,O B I I I O O O O O O O O O O O O
Extending the lexical coverage of a treebank - derived parser using an external lexicon is relevant for any language with a small treebank .,O O B I O O B I I I O O O B O O O O O O O O B O
We present novel methods for analyzing the activation patterns of recurrent neural networks from a linguistic point of view and explore the types of linguistic structure they learn .,O O O B O B I I I O B I I O O B I I I O O O B I I I O O O
"As a case study , we use a standard standalone language model , and a multi - task gated recurrent network architecture consisting of two parallel pathways with shared word embeddings : The Visual pathway is trained on predicting the representations of the visual scene corresponding to an input sentence , and the Textual pathway is trained to predict the next word in the same sentence .",O O O O O O O O B I I I O O O B I I I I I I O O O O O O O B I O O B I O B O B I I O O O O O O O B I O O O B I O B O B I I I O O O B O
We propose a method for estimating the amount of contribution of individual tokens in the input to the final prediction of the networks .,O O O B O O O O O O O O B O O B O O B I O O B O
"Using this method , we show that the Visual pathway pays selective attention to lexical categories and grammatical functions that carry semantic information , and learns to treat word types differently depending on their grammatical function and their position in the sequential structure of the sentence .",O O B O O O O O B I O O O O B I O B I O B I I O O B O O B O O O O O B I O O B I I I I O O O O
"In contrast , the language models are comparatively more sensitive to words with a syntactic function .",O O O O B I O O O O O B I I I I O
"Further analysis of the most informative n - gram contexts for each model shows that in comparison with the VISUAL pathway , the language models react more strongly to abstract contexts that represent syntactic constructions .",O O O O O O B I I I O O B O O O O O O B I O O B I O O O O O B O B I I O
"Although there has been much theoretical work on using various information status distinctions to explain the form of references in written text , there have been few studies that attempt to automatically learn these distinctions for generating references in the context of computer - regenerated text .",O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O B I I I O
"In this article , we present a model for generating references to people in news summaries that incorporates insights from both theory and a corpus analysis of human written summaries .",O O O O O O O B O O O O O O O O O O O O O O O O B I O O O O O
"In particular , our model captures how two properties of a person referred to in the summary — familiarity to the reader and global salience in the news story — affect the content and form of the initial reference to that person in a summary .",O O O O B O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O
We demonstrate that these two distinctions can be learned from a typical input for multi - document summarization and that they can be used to make regeneration decisions that improve the quality of extractive summaries .,O O O O O O O O O O O O O O B I I I O O O O O O O O B O O O O O O B I O
"Ensemble methods using multiple classifiers have proven to be among the most successful approaches for the task of Native Language Identification ( NLI ) , achieving the current state of the art .",B I O O B O O O O O O O O O O O O O B I I O B O O O O O B I I I O
"However , a systematic examination of ensemble methods for NLI has yet to be conducted .",O O O B I O B I O B O O O O O O
"Additionally , deeper ensemble architectures such as classifier stacking have not been closely evaluated .",O O O B I O O B I O O O O O O
"We present a set of experiments using three ensemble - based models , testing each with multiple configurations and algorithms .",O O O O O O O B I I I I O O O O O B O B O
"This includes a rigorous application of meta - classification models for NLI , achieving state - of - the - art results on several large data sets , evaluated in both intra - corpus and cross - corpus modes .",O O O O O O B I I I O B O O B I I I I I I O O O O B I O O O O B I I O B I I I O
"In parsing with Tree Adjoining Grammar ( TAG ) , independent derivations have been shown by Schabes and Shieber ( 1994 ) to be essential for correctly supporting syntactic analysis , semantic interpretation , and statistical language modeling .",O B O B I I O B O O B I O O O O O O O O O O O O O O O O B I O B I O O B I I O
"However , the parsing algorithm they propose is not directly applicable to Feature - Based TAGs ( FB - TAG ) .",O O O B I O O O O O O O B I I I O B I I O O
We provide a recognition algorithm for FB - TAG that supports both dependent and independent derivations .,O O O B I O B I I O O O B O B I O
The resulting algorithm combines the benefits of independent derivations with those of Feature - Based grammars .,O O B O O O O B I O O O B I I I O
"In particular , we show that it accounts for a range of interactions between dependent vs. independent derivation on the one hand , and syntactic constraints , linear ordering , and scopal vs. nonscopal semantic dependencies on the other hand .",O O O O O O O O O O O O O O B O B I O O O O O O B I O B I O O B O B I I O O O O O
Frame semantics is a linguistic theory that has been instantiated for English in the FrameNet lexicon .,B I O O B I O O O O O B O O B I O
"We solve the problem of frame - semantic parsing using a two - stage statistical model that takes lexical targets ( i.e. , content words and phrases ) in their sentential contexts and predicts frame - semantic structures .",O O O O O O O B I O O O O O B I O O B O O O O O B O B O O O B I O B I O B I O
"Given a target in context , the first stage disambiguates it to a semantic frame .",O O O O B O O O O B O O O B I O
This model uses latent variables and semi - supervised learning to improve frame disambiguation for targets unseen at training time .,O B O B I O B I I I O O B I O O O O B I O
The second stage finds the target 's locally expressed semantic arguments .,O O O O O O O O O B I O
"At inference time , a fast exact dual decomposition algorithm collectively predicts all the arguments of a frame at once in order to respect declaratively stated linguistic constraints , resulting in qualitatively better structures than naïve local predictors .",O B I O O O O O B I O B O O B O O B O O O O O O O O B I O O O O O O O B I I O
Both components are feature - based and discriminatively trained on a small set of annotated frame - semantic parses .,O O O B O O O O B O O O O O B I O B I O
"On the SemEval 2007 benchmark data set , the approach , along with a heuristic identifier of frame - evoking targets , outperforms the prior state of the art by significant margins .",O O B O B I I O O O O O O O B I O B O O B O B O O O O O O O O O O
"Additionally , we present experiments on the much larger FrameNet 1.5 data set .",O O O O O O O O O B O B I O
We have released our frame - semantic parser as open - source software .,O O O O O O B I O O O O O O
Probabilistic topic modeling is a common first step in crosslingual tasks to enable knowledge transfer and extract multilingual features .,B I I O O O O O O B I O O B I O O B I O
"Although many multilingual topic models have been developed , their assumptions about the training corpus are quite varied , and it is not clear how well the different models can be utilized under various training conditions .",O O B I O O O O O O O O O B I O O O O O O O O O O O O O B O O O O O B I O
"In this article , the knowledge transfer mechanisms behind different multilingual topic models are systematically studied , and through a broad set of experiments with four models on ten languages , we provide empirical insights that can inform the selection and future development of multilingual topic models .",O O O O O B I I O O B I I O O O O O O O O O O B O O B O O O O O O O O O O O O O O O O O B I I O
"Given a constraint set with k constraints in the framework of Optimality Theory ( OT ) , what is its capacity as a classification scheme for linguistic data ? One useful measure of this capacity is the size of the largest data set of which each subset is consistent with a different grammar hypothesis .",O O B I O O B O O B I I I O B O O O O O O O O B I O B I O O O B O O O O O O O O O O O O O O B O O O O O B I O
This measure is known as the Vapnik Chervonenkis dimension ( VCD ) and is a standard complexity measure for concept classes in computational learnability theory .,O B O O O O B I I O B O O O O O B I O B I O B I I O
"In this work , I use the three valued logic of Elementary Ranking Conditions to show that the VCD of Optimality Theory with k constraints is k 1 .",O O O O O O O B I I I I I I O O O O B O B I O O B O O O O
Analysis of OT in terms of the VCD establishes that the complexity of OT is a well behaved function of k and that the ‘ hardness ’ of learning in OT is linear in k for a variety of frameworks that employ probabilistic definitions of learnability .,O O B O O O O B O O O O O B O O B I I O B O O O O O O O O O B O B O O O O O O B O O B I O B O
This paper is concerned with automatic generation of all possible questions from a topic of interest .,O O O O O B I O O O O O O O O O O
"Specifically , we consider that each topic is associated with a body of texts containing useful information about the topic .",O O O O O O O O O O O O O O O O O O O O O
"Then , questions are generated by exploiting the named entity information and the predicate argument structures of the sentences present in the body of texts .",O O O O B O O O B I I O O B I I O O O O O O O O O O
The importance of the generated questions is measured using Latent Dirichlet Allocation by identifying the subtopics ( which are closely related to the original topic ) in the given body of texts and applying the Extended String Subsequence Kernel to calculate their similarity with the questions .,O O O O B I O O O B I I O O O O O O O O O O O O O O O O O O O O O O O B I I I O O O B O O O O
We also propose the use of syntactic tree kernels for the automatic judgment of the syntactic correctness of the questions .,O O O O O O B I I O O B I O O B I O O O O
The questions are ranked by considering both their importance ( in the context of the given body of texts ) and syntactic correctness .,O O O O O O O O B O O O O O O O O O O O O B I O
"To the best of our knowledge , no previous study has accomplished this task in our setting .",O O O O O O O O O O O O O O O O O O
A series of experiments demonstrate that the proposed topic - to - question generation approach can significantly outperform the state - of - the - art results .,O O O O O O O O O O O O B I I O O O O O O O O O O O O O
We study the parsing complexity of Combinatory Categorial Grammar ( CCG ) in the formalism of Vijay - Shanker and Weir ( 1994 ) .,O O O B I O B I I O B O O O B I I I I I I O O O O
"As our main result , we prove that any parsing algorithm for this formalism will take in the worst case exponential time when the size of the grammar , and not only the length of the input sentence , is included in the analysis .",O O O O O O O O O B I O O B O O O O O O B O O O O O O B O O O O O O O O B I O O O O O O O
"This sets the formalism of Vijay - Shanker and Weir ( 1994 ) apart from weakly equivalent formalisms such as Tree Adjoining Grammar , for which parsing can be performed in time polynomial in the combined size of grammar and input sentence .",O O O B I I I I I I O O O O O B I I O O B I I O O O B O O O O B I O O O O O B O B I O
"Our results contribute to a refined understanding of the class of mildly context - sensitive grammars , and inform the search for new , mildly context - sensitive versions of CCG .",O O O O O O O O O B O B I I I I O O O O O O O O B I I I I I I O
Evaluation and error analysis of machine translation output are important but difficult tasks .,B O O O O B I O O O O O O O
"In this article , we propose a framework for automatic error analysis and classification based on the identification of actual erroneous words using the algorithms for computation of Word Error Rate ( WER ) and Position - independent word Error Rate ( PER ) , which is just a very first step towards development of automatic evaluation measures that provide more specific information of certain translation problems .",O O O O O O O O O B I I O B O O O O O O O O O O O O O O B I I O B O O B I I B I I O B O O O O O O O O O O O O B I O O O O O O O O O O O
The proposed approach enables the use of various types of linguistic knowledge in order to classify translation errors in many different ways .,O O O O O O O O O O O O O O O O O O O O O O O
"This work focuses on one possible set - up , namely , on five error categories : inflectional errors , errors due to wrong word order , missing words , extra words , and incorrect lexical choices .",O O O O O O O O O O O O O O O O O B I O O O O O O O O O O O O O O O O B I O
"For each of the categories , we analyze the contribution of various POS classes .",O O O O O O O O O O O O B O O
"We compared the results of automatic error analysis with the results of human error analysis in order to investigate two possible applications : estimating the contribution of each error type in a given translation output in order to identify the main sources of errors for a given translation system , and comparing different translation outputs using the introduced error categories in order to obtain more information about advantages and disadvantages of different systems and possibilites for improvements , as well as about advantages and disadvantages of applied methods for improvements .",O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O B I O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O
"We used Arabic – English Newswire and Broadcast News and Chinese – English Newswire outputs created in the framework of the GALE project , several Spanish and English European Parliament outputs generated during the TC - Star project , and three German – English outputs generated in the framework of the fourth Machine Translation Workshop .",O O O O O O O O O O O O O O O O O O O O O B O O O O O O O O O O O O B I I O O O O O O O O O O O O O O O B I I O
"We show that our results correlate very well with the results of a human error analysis , and that all our metrics except the extra words reflect well the differences between different versions of the same translation system as well as the differences between different translation systems .",O O O O O O O O O O O O O B I I O O O O O O O O O O O O O O O O O O O O B I O O O O O O O B I O
Word Sense Disambiguation ( WSD ) systems automatically choose the intended meaning of a word in context .,B I I O B O B B O O O O O O B O B O
In this article we present a WSD algorithm based on random walks over large Lexical Knowledge Bases ( LKB ) .,O O O O O O B I O O O O O O B I I O B O O
We show that our algorithm performs better than other graph - based methods when run on a graph built from WordNet and eXtended WordNet .,O O O O B O O O O B O O O O O O O B O O B O B I O
Our algorithm and LKB combination compares favorably to other knowledge - based approaches in the literature that use similar knowledge on a variety of English data sets and a data set on Spanish .,O B O B I O O O O B I I I O O O O O O B O O O O B B I O O B I O B O
We include a detailed analysis of the factors that affect the algorithm .,O O O O B O O O O O O B O
"The algorithm and the LKBs used are publicly available , and the results easily reproducible .",O B O O B O O O O O O O O O O O
"Text - to - SQL is the problem of converting a user question into an SQL query , when the question and database are given .",B I I I I O O O O O O O O O O B I O O O O O O O O O
"In this article , we present a neural network approach called RYANSQL ( Recursively Yielding Annotation Network for SQL ) to solve complex Text - to - SQL tasks for cross - domain databases .",O O O O O O O B I O O B O B I I I I I O O O O B I I I I I O B I I O O
Statement Position Code ( SPC ) is defined to transform a nested SQL query into a set of non - nested SELECT statements ; a sketch - based slot - filling approach is proposed to synthesize each SELECT statement for its corresponding SPC .,B I I O B O O O O O O B B I O O O O B I I B I O O B I I B I I O O O O O O B I O O O B O
"Additionally , two input manipulation methods are presented to improve generation performance further .",O O O B O O O O O O O O O O
RYANSQL achieved competitive result of 58.2 % accuracy on the challenging Spider benchmark .,B O O O O O O O O O O B I O
"At the time of submission ( April 2020 ) , RYANSQL v2 , a variant of original RYANSQL , is positioned at 3rd place among all systems and 1st place among the systems not using database content with 60.6 % exact matching accuracy .",O O O O O O O O O O B O O O O O O B O O O O O O O O O O O O O O O O O O O O O O O B I O
The source code is available at https://github.com/kakaoenterprise/RYANSQL .,O B I O O O O O
Information graphics ( such as bar charts and line graphs ) play a vital role in many multimodal documents .,B I O O O B I O B I O O O O O O O B I O
"The majority of information graphics that appear in popular media are intended to convey a message and the graphic designer uses deliberate communicative signals , such as highlighting certain aspects of the graphic , in order to bring that message out .",O O O B I O O O O O O O O O O O O O B I O B I I O O O O O O O O O O O O O O O O O O
"The graphic , whose communicative goal ( intended message ) is often not captured by the document ’s accompanying text , contributes to the overall purpose of the document and can not be ignored .",O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O
This article presents our approach to providing the high - level content of a non - scientiﬁc information graphic via a brief textual summary which includes the intended message and the salient features of the graphic .,O O O O O O O O B I I I O O O O O O O O O O O O O O O O O O O B I O O O O
"This work brings together insights obtained from empirical studies in order to determine what should be contained in the summaries of this form of non - linguistic input data , and how the information required for realizing the selected content can be extracted from the visual image and the textual components of the graphic .",O O O O O O O O O O O O O O O O O O O B O O O O B I I I I O O O O O O O O O O O O O O O O B I O O B I O O O O
This work also presents a novel bottom – up generation approach to simultaneously construct the discourse and sentence structures of textual summaries by leveraging different discourse related considerations such as the syntactic complexity of realized sentences and clause embeddings .,O O O O O O B I I I I O O O O B O B I O O O O O O B O O O O O B I O B I O B I O
The effectiveness of our work was validated by different evaluation studies .,O O O O O O O O O O O O
"This article describes a neural semantic parser that maps natural language utterances onto logical forms that can be executed against a task - specific environment , such as a knowledge base or a database , to produce a response .",O O O O B I I O O B I B O B I O O O O O O O O O O O O O O B I O O B O O O O O O
"The parser generates tree - structured logical forms with a transition - based approach , combining a generic tree - generation algorithm with domain - general grammar defined by the logical language .",O B O B I B I I O O B I I I O O O B I O B I O B O B I O O O B I O
"The generation process is modeled by structured recurrent neural networks , which provide a rich encoding of the sentential context and generation history for making predictions .",O O O O O O B I I I O O O O O B O O B I O O O O O O O
"To tackle mismatches between natural language and logical form tokens , various attention mechanisms are explored .",O O O O B I O B I I O O B I O O O
"Finally , we consider different training settings for the neural semantic parser , including fully supervised training where annotated logical forms are given , weakly supervised training where denotations are provided , and distant supervision where only unlabeled sentences and a knowledge base are available .",O O O O O B I O O B I I O O B I I O B B I O O O B I I O B O O O O B I O O B I O O B I O O O
Experiments across a wide range of data sets demonstrate the effectiveness of our parser .,O O O O O O O O O O O O O B O
Multiword expressions lie at the syntax / semantics interface and have motivated alternative theories of syntax like Construction Grammar .,B I O O O B O B O O O O O O O B O B I O
"Until now , however , syntactic analysis and multiword expression identification have been modeled separately in natural language processing .",O O O O O B I O B I I O O O O O B I I O
We develop two structured prediction models for joint parsing and multiword expression identification .,O O O B I I O B I O B I I O
"The first is based on context - free grammars and the second uses tree substitution grammars , a formalism that can store larger syntactic fragments .",O O O O O B I I I O O O O B I I O O B O O O O B I O
Our experiments show that both models can identify multiword expressions with much higher accuracy than a state - of - the - art system based on word co - occurrence statistics .,O O O O O B O O B I O O O B O O B I I I I I I O O O B I I I O O
"We experiment with Arabic and French , which both have pervasive multiword expressions .",O O O O O O O O O O B I I O
"Relative to English , they also have richer morphology , which induces lexical sparsity in finite corpora .",O O O O O O O O B O O O B I O O B O
"To combat this sparsity , we develop a simple factored lexical representation for the context - free parsing model .",O O O B O O O O O B I I O O B I I I I O
Morphological analyses are automatically transformed into rich feature tags that are scored jointly with lexical items .,B O O O O O O B I O O O O O B I O
"This technique , which we call a factored lexicon , improves both standard parsing and multiword expression identification accuracy .",O O O O O O O B I O O O O B O B I I B O
The formalism for Lexical - Functional Grammar ( LFG ) was introduced in the 1980s as one of the first constraint - based grammatical formalisms for natural language .,O B O B I I I O B O O O O O O O O O O O B I I I I O B I O
It has led to substantial contributions to the linguistic literature and to the construction of large - scale descriptions of particular languages .,O O O O O O O O B I O O O O O O O O O O O O O
"Investigations of its mathematical properties have shown that , without further restrictions , the recognition , emptiness , and generation problems are undecidable , and that they are intractable in the worst case even with commonly applied restrictions .",O O O O O O O O O O O O O O O O O O O B I O B O O O O O B O O O O O O O O O O
"However , grammars of real languages appear not to invoke the full expressive power of the formalism , as indicated by the fact that algorithms and implementations for recognition and generation have been developed that run — even for broad - coverage grammars — in typically polynomial time .",O O B O O O O O O O O O B I O O B O O O O O O O B O O O B O B O O O O O O O O B I I I O O O B I O
This article formalizes some restrictions on the notation and its interpretation that are compatible with conventions and principles that have been implicit or informally stated in linguistic theory .,O O O O O O O O O O O O O O O O O O O O O O O O O O B I O
"We show that LFG grammars that respect these restrictions , while still suitable for the description of natural languages , are equivalent to linear context - free rewriting systems and allow for tractable computation .",O O O B I O O O O O O O O O O O O B I O O O O B I I I I I O O O B I O
"In this article , we conduct an empirical investigation of translation divergences between Chinese and English relying on a parallel treebank .",O O O O O O O O B I I I O B O B O O O B I O
"To do this , we first devise a hierarchical alignment scheme where Chinese and English parse trees are aligned in a way that eliminates conflicts and redundancies between word alignments and syntactic parses to prevent the generation of spurious translation divergences .",O O O O O O B I I I I O B O B B I I I O O O O O O O O O B I O B I O O O B O O B I O
"Using this Hierarchically Aligned Chinese – English Parallel Treebank ( HACEPT ) , we are able to semi - automatically identify and categorize the translation divergences between the two languages and quantify each type of translation divergence .",O O B I I I I I I O B O O O O O O B I I I O B O B I O O O B O O O O O B I O
Our results show that the translation divergences are much broader than described in previous studies that are largely based on anecdotal evidence and linguistic knowledge .,O O O O O B I O O O O O O O O O O O O O B I O B I O
"The distribution of the translation divergences also shows that some high - profile translation divergences that motivate previous research are actually very rare in our data , whereas other translation divergences that have previously received little attention actually exist in large quantities .",O B I I I I O O O O O O O B I O O O O O O O O O O B O O O B I O O O O O O O O O O O O
"We also show that HACEPT allows the extraction of syntax - based translation rules , most of which are expressive enough to capture the translation divergences , and point out that the syntactic annotation in existing treebanks is not optimal for extracting such translation rules .",O O O O B O O B I I I I I I O O O O O O O O B I I I O O O O O O B I O O B O O O O B O B I O
We also discuss the implications of our study for attempts to bridge translation divergences by devising shared semantic representations across languages .,O O O O O O O O O O O O B I O B I I I I I O
"Our quantitative results lend further support to the observation that although it is possible to bridge some translation divergences with semantic representations , other translation divergences are open - ended , thus building a semantic representation that captures all possible translation divergences may be impractical .",O O O O O O O O O O O O O O O O O B I O B I O O B I O O O O O O B I I I O B I I I I O O O O
"In this article , we present a novel machine translation model , the Operation Sequence Model ( OSM ) , which combines the benefits of phrase - based and N - gram - based statistical machine translation ( SMT ) and remedies their drawbacks .",O O O O O O O O B I I O O B I I O B O O O O O O O B O O O B I I O O B I I O B O O O O O O
The model represents the translation process as a linear sequence of operations .,O O O O B I O O B I O O O
The sequence includes not only translation operations but also reordering operations .,O B O O O B I O O B I O
"As in N - gram - based SMT , the model is : ( i ) based on minimal translation units , ( ii ) takes both source and target information into account , ( iii ) does not make a phrasal independence assumption , and ( iv ) avoids the spurious phrasal segmentation problem .",O O B I I O O B O O B O O O O O O O O B I O O O O O O O O B I O O O O O O O O O O B I I O O O O O O O O B I O O
"As in phrase - based SMT , the model ( i ) has the ability to memorize lexical reordering triggers , ( ii ) builds the search graph dynamically , and ( iii ) decodes with large translation units during search .",O O B O I B O O B O O O O O O O O B I I O O O O O O B I O O O O O O O O O B I O O O
"The unique properties of the model are ( i ) its strong coupling of reordering and translation where translation and reordering decisions are conditioned on n previous translation and reordering decisions , and ( ii ) the ability to model local and long - range reorderings consistently .",O O O O O B O O O O O O O O B O B O B O B I O O O O O B O B I O O O O O O O O O O O O O O B O O
"Using BLEU as a metric of translation accuracy , we found that our system performs significantly better than state - of - the - art phrase - based systems ( Moses and Phrasal ) and N - gram - based systems ( Ncode ) on standard translation tasks .",O B O O B O B I O O O O O O O O O O O O O O O O O B O I I O B O B O O B I I O O O O B O O O B I O
We compare the reordering component of the OSM to the Moses lexical reordering model by integrating it into Moses .,O O O B I O O B O O B I I I O O O O B O
Our results show that OSM outperforms lexicalized reordering on all translation tasks .,O O O O B O B I O O B I O
The translation quality is shown to be improved further by learning generalized representations with a POS - based OSM .,O B I O O O O B O O B I I O O B O O B O
This article presents a novel approach for readability assessment through sorting .,O O O O O O O B I O B O
"A comparator that judges the relative readability between two texts is generated through machine learning , and a given set of texts is sorted by this comparator .",O B O O O O B O O O O O O B I O O O O O O O O O O O B O
"Our proposal is advantageous because it solves the problem of a lack of training data , because the construction of the comparator only requires training data annotated with two reading levels .",O O O O O O O O O O O O O B I O O O O O O B O O B I B O O B I O
The proposed method is compared with regression methods and a state - of - the art classification method .,O O O O O O B I O O B I I I I I B I O
"Moreover , we present our application , called Terrace , which retrieves texts with readability similar to that of a given input text .",O O O O O O O O O O O O O O B O O O O O O O O O
"Manually annotated corpora are indispensable resources , yet for many annotation tasks , such as the creation of treebanks , there exist multiple corpora with different and incompatible annotation guidelines .",B I I O O O O O O O B I O O O O O O B O O O O B O O O O B I O
"This leads to an inefficient use of human expertise , but it could be remedied by integrating knowledge across corpora with different annotation guidelines .",O O O O O O O O O O O O O O O O O O O B O O B I O
"In this article we describe the problem of annotation adaptation and the intrinsic principles of the solutions , and present a series of successively enhanced models that can automatically adapt the divergence between different annotation formats .",O O O O O O O O B I O O B I O O O O O O O O O O O B O O B O O B O O B I O
We evaluate our algorithms on the tasks of Chinese word segmentation and dependency parsing .,O O O B O O O O O B I O B I O
"For word segmentation , where there are no universal segmentation guidelines because of the lack of morphology in Chinese , we perform annotation adaptation from the much larger People s Daily corpus to the smaller but more popular Penn Chinese Treebank .",O B I O O O O O B I I O O O O O B O O O O O B I O O O O O O O B O O O O O O B I I O
"For dependency parsing , we perform annotation adaptation from the Penn Chinese Treebank to a semantics - oriented Dependency Treebank , which is annotated using significantly different annotation guidelines .",O B I O O O B I O O B I I O O B O O B I O O O B O O O B I O
Current machine translation ( MT ) systems are still not perfect .,O B I O B O O O O O O O
"In practice , the output from these systems needs to be edited to correct errors .",O O O O B O O O O O O O O O B O
"A way of increasing the productivity of the whole translation process ( MT plus human work ) is to incorporate the human correction activities within the translation process itself , thereby shifting the MT paradigm to that of computer assisted translation .",O O O O O O O O O B I O B O O O O O O O O O O O O O B I O O O B O B I O O O B I I O
"This model entails an iterative process in which the human translator activity is included in the loop : In each iteration , a prefix of the translation is validated ( accepted or amended ) by the human and the system computes its best ( or n best ) translation suffix hypothesis to complete this prefix .",O B O O B I O O O B I I O O O O O O O O B O O B O O O O B O B O B O O O O O O O O O O O O O O O B I I O O O B O
A successful framework for MT is the so called statistical ( or pattern recognition ) framework .,O O B O B O O O O O O O O O O B O
"Interestingly , within this framework , the adaptation of MT systems to the interactive scenario affects mainly the search process , allowing a great reuse of successful techniques and models .",O O O O B O O O O B I O O O O O O O O O O O O O O O O I O B O
"In this article , alignment templates , phrase based models , and stochastic finite state transducers are used to develop computer assisted translation systems .",O O O O B I O B I I O O B I I I O O O O B I I I O
These systems were assessed in a European project ( Trans Type2 ) in two real tasks : The translation of printer manuals ; manuals and the translation of the Bulletin of the European Union .,O O O O O O O O O B I O O O O O O O O O O O O O O O O O O O O O O O O
"In each task , the following three pairs of languages were involved ( in both translation directions ) : English Spanish , English German , and English French .",O O O O O O O O O O O O O O O O O O O O O O O O O O O O O
Word alignment plays an important role in many NLP tasks as it indicates the correspondence between words in a parallel text .,B I O O O O O O B I O O O O O O O O O B I O
"Although widely used to align large bilingual corpora , generative models are hard to extend to incorporate arbitrary useful linguistic information .",O O O O B O B I O B I O O O O O O O O B I O
This article presents a discriminative framework for word alignment based on a linear model .,O O O O B I O B I O O O B I O
"Within this framework , all knowledge sources are treated as feature functions , which depend on a source language sentence , a target language sentence , and the alignment between them .",O O B O O B I O O O B I O O O O O B I I O O B I I O O O B O O O
We describe a number of features that could produce symmetric alignments .,O O O O O B O O O B I O
Our model is easy to extend and can be optimized with respect to evaluation metrics directly .,O O O O O O O O O O O O O B I O O
The model achieves state - of - the - art alignment quality on three word alignment shared tasks for five language pairs with varying divergence and richness of resources .,O O O B I I I I I I B I O O B I O O O O B I O O O O O O O O
We further show that our approach improves translation performance for various statistical machine translation systems .,O O O O O O O B I O O B I I I O
Linguistic steganography is concerned with hiding information in natural language text .,B I O O O O B O B I I O
One of the major transformations used in linguistic steganography is synonym substitution .,O O O O O O O B I O B I O
"However , few existing studies have studied the practical application of this approach .",O O O O O O O O O O O O O O
In this article we propose two improvements to the use of synonym substitution for encoding hidden bits of information .,O O O O O O O O O O O B I O B I I O B O
"First , we use the Google n - gram corpus for checking the applicability of a synonym in context , and we evaluate this method using data from the SemEval lexical substitution task and human annotated data .",O O O O O O B I I I O O O O O O B O B O O O B O O O B O O B I I O O O B B O
"Second , we address the problem that arises from words with more than one sense , which creates a potential ambiguity in terms of which bits are represented by a particular word .",O O O O O O O O O B O O O O O O O O O O B O O O O O O O O O O B O
"We develop a novel method in which words are the vertices in a graph , synonyms are linked by edges , and the bits assigned to a word are determined by a vertex coding algorithm .",O O O O O O O B O O O O O B O B O O O O O O O O O O O B O O O O B I I O
"This method ensures that each word represents a unique sequence of bits , without cutting out large numbers of synonyms , and thus maintains a reasonable embedding capacity .",O O O O O B O O B I O O O O O O O O O B O O O O O O B O O
Bilexical context - free grammars ( 2 - LCFGs ) have proved to be accurate models for statistical natural language parsing .,B I I I I O B I I O O O O O O B O B I I I O
"Existing dynamic programming algorithms used to parse sentences under these models have running time of O(∣w∣4 ) , where w is the input string .",O B I I O O B O O O B O B I O O O O O O O O O B O
"A 2 - LCFG is splittable if the left arguments of a lexical head are always independent of the right arguments , and vice versa .",O B I I O B O O O B O O B I O O O O O O B O O O O O
"When a 2 - LCFGs is splittable , parsing time can be asymptotically improved to O(∣w∣3 ) .",O O B I I O B O B O O O B O O O O O
Testing this property is therefore of central interest to parsing efficiency .,O O O O O O O O O B O O
"In this article , however , we show the negative result that splittability of 2 - LCFGs is undecidable .",O O O O O O O O O O O O B O B I I O B O
"Understanding predictions made by deep neural networks is notoriously difficult , but also crucial to their dissemination .",B I O O B I I O O O O O O O O O O O
"As all machine learning – based methods , they are as good as their training data , and can also capture unwanted biases .",O O B I I I I O O O O O O O B I O O O O O O B O
"While there are tools that can help understand whether such biases exist , they do not distinguish between correlation and causation , and might be ill - suited for text - based models and for reasoning about high - level language concepts .",O O O O O O O O O O B O O O O O O O O O O O O O O O O O O B I I I O O O O B I I I I O
"A key problem of estimating the causal effect of a concept of interest on a given model is that this estimation requires the generation of counterfactual examples , which is challenging with existing generation technology .",O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O B I O
"To bridge that gap , we propose CausaLM , a framework for producing causal model explanations using counterfactual language representation models .",O O O O O O O B O O O O O B I I O B I I I O
Our approach is based on fine - tuning of deep contextualized embedding models with auxiliary adversarial tasks derived from the causal graph of the problem .,O O O O O B I I O B I I I O B I I O O O B I O O O O
"Concretely , we show that by carefully choosing auxiliary adversarial pre - training tasks , language representation models such as BERT can effectively learn a counterfactual representation for a given concept of interest , and be used to estimate its true causal effect on model performance .",O O O O O O O O B I I I I I O B I I O O B O O O O B I O O O O O O O O O O O O O O O O O B I O
"A byproduct of our method is a language representation model that is unaffected by the tested concept , which can be useful in mitigating unwanted bias ingrained in the data .",O O O O O O O B I I O O O O O O O O O O O O O O O B O O O O O
The general problem of finding satisfying solutions to constraint - based underspecified representations of quantifier scope is NP - complete .,O O O O O O O O B I I I I I I I O B I I O
"Existing frameworks , including Dominance Graphs , Minimal Recursion Semantics , and Hole Semantics , have struggled to balance expressivity and tractability in order to cover real natural language sentences with efficient algorithms .",O B O O B I O B I I O O B I O O O O O B O B O O O O O B I I O B I O
"We address this trade - off with a general principle of coherence , which requires that every variable introduced in the domain of discourse must contribute to the overall semantics of the sentence .",O O O O O O O O B I I I O O O O O O O O O O O O O O O O O B O O O O
"We show that every underspecified representation meeting this criterion can be efficiently processed , and that our set of representations subsumes all previously identified tractable sets .",O O O O B I O O O O O O O O O O O O O O O O O O B I O
"Most morphologically rich languages with free word order use case systems to mark the grammatical function of nominal elements , especially for the core argument functions of a verb .",O B I I O B I I O B I O O O B I O B I O O O O B I I O O O O
The standard pipeline approach in syntactic dependency parsing assumes a complete disambiguation of morphological ( case ) information prior to automatic syntactic analysis .,O O B I O B I I O O O B O B O B O O O O B I I O
"Parsing experiments on Czech , German , and Hungarian show that this approach is susceptible to propagating morphological annotation errors when parsing languages displaying syncretism in their morphological case paradigms .",B I O O O O O O O O O O O O O O O B I O O B O O O O O B I O O
We develop a different architecture where we use case as a possibly underspecified filtering device restricting the options for syntactic analysis .,O O O O O O O O B O O O O O O O O O O B I O
Carefully designed morpho - syntactic constraints can delimit the search space of a statistical dependency parser and exclude solutions that would violate the restrictions overtly marked in the morphology of the words in a given sentence .,O O B I I I O O O O O O O B I I O O O O O O O O O O O O B O O O O O O O O
"The constrained system outperforms a state - of - the - art data - driven pipeline architecture , as we show experimentally , and , in addition , the parser output comes with guarantees about local and global morpho - syntactic wellformedness , which can be useful for downstream applications .",O O O O O B I I I I I I B I I B I O O O O O O O O O O O O B I O O O O O O B I I I I O O O O O O O O O
Generating responses that take user preferences into account requires adaptation at all levels of the generation process .,O O O O O O O O O O O O O O O B I O
"This article describes a multi - level approach to presenting user - tailored information in spoken dialogues which brings together for the first time multi - attribute decision models , strategic content planning , surface realization that incorporates prosody prediction , and unit selection synthesis that takes the resulting prosodic structure into account .",O O O O B I I I O O B I I I O B I O O O O O O O B I I I I O B I I O B I O O B I O O B I I O O O O B I O O O
"The system selects the most important options to mention and the attributes that are most relevant to choosing between them , based on the user model .",O O O O O O O O O O O O O O O O O O O O O O O O B I O
Multiple options are selected when each offers a compelling trade - off .,O O O O O O O O O B I I O
"To convey these trade - offs , the system employs a novel presentation strategy which straightforwardly lends itself to the determination of information structure , as well as the contents of referring expressions .",O O O B I I O O O O O B I I O O O O O O O O B I O O O O O O O B I O
"During surface realization , the prosodic structure is derived from the information structure using Combinatory Categorial Grammar in a way that allows phrase boundaries to be determined in a flexible , data - driven fashion .",O B I O O B I O O O O B I O B I I O O O O O B I O O O O O O O B I I I O
This approach to choosing pitch accents and edge tones is shown to yield prosodic structures with significantly higher acceptability than baseline prosody prediction models in an expert evaluation .,O O O O B I O B I O O O O B I O O O O O B I I I O O O O O
"These prosodic structures are then shown to enable perceptibly more natural synthesis using a unit selection voice that aims to produce the target tunes , in comparison to two baseline synthetic voices .",O B I O O O O O O O B I O O B I I O O O O O B I O O O O O B B I O
An expert evaluation and f0 analysis confirm the superiority of the generator - driven intonation and its contribution to listeners ' ratings .,O O O O B I O O O O O B I I I O O O O O O O O
Hashtags are creative labels used in micro - blogs to characterize the topic of a message / discussion .,B O O B O O B I I O B I I O O O O O O
"Regardless of the use for which they were originally intended , hashtags can not be used as a means to cluster messages with similar content .",O O O O O O O O O O O B O O O O O O O O B I O B I O
"First , because hashtags are created in a spontaneous and highly dynamic way by users in multiple languages , the same topic can be associated with different hashtags , and conversely , the same hashtag may refer to different topics in different time periods .",O O O B O O O O O O O O O O O O B I O O O B O O O O O B O O O O O O B O O O B I O O O O O
"Second , contrary to common words , hashtag disambiguation is complicated by the fact that no sense catalogs ( e.g. , Wikipedia or WordNet ) are available ; and , furthermore , hashtag labels are difficult to analyze , as they often consist of acronyms , concatenated words , and so forth .",O O O O B I O B I O O O O O O O B I O O O B O B O O O O O O O O B I O O O O O O O O O O B O B I O O O O O
"A common way to determine the meaning of hashtags has been to analyze their context , but , as we have just pointed out , hashtags can have multiple and variable meanings .",O O O O O O O O B O O O B I I O O O O O O O O O O B O O B I I I O
"In this article , we propose a temporal sense clustering algorithm based on the idea that semantically related hashtags have similar and synchronous usage patterns .",O O O O O O O B I I I O O O O O B O B O B I I I I O
Languages vary in the way stress is assigned to syllables within words .,O O O O O B O O O O O O O
This article investigates the learnability of stress systems in a wide range of languages .,O O O O B O B I O O O O O O O
"The stress systems can be described using finite - state automata with symbols indicating levels of stress ( primary , secondary , or no stress ) .",O B I O O O O B I I I O O O B I I O O O O O O O O O O
Finite - state automata have been the focus of research in the area of grammatical inference for some time now .,B I I I O O O O O O O O O O B I O O O O O
It has been shown that finite - state machines are learnable from examples using state - merging .,O O O O O B I I I O B O O O B I I O
"One such approach , which aims to learn k - testable languages , has been applied to stress systems with some success .",O O O O O O O O B I I I O O O O O B I O O O O
The family of k - testable languages has been shown to be efficiently learnable ( in polynomial time ) .,O O O B I I I O O O O O O B O O B I O O
"Here , we extend this approach to k , l - local languages by taking not only left context , but also right context , into account .",O O O O O O O B O B I I I O O O O B I O O O B I O O O O
We consider empirical results testing the performance of our learner using various amounts of context ( corresponding to varying definitions of phonological locality ) .,O O O O O O O O O B O O O O B O O O O O O B I O O
Our results show that our approach of learning stress patterns using state - merging is more reliant on left context than on right context .,O O O O O O O O B I O B I I O O O O B I O O B I O
"Additionally , some stress systems fail to be learned by our learner using either the left - context k - testable or the left - and - right - context k , l - local learning system .",O O O B I O O O O O O B O O O B I I I I I O O B I I I I I I I O B I I I I O
"A more complex merging strategy , and hence grammar representation , is required for these stress systems .",O O O B I O O O B I O O O O O B I O
"We present LESSLEX , a novel multilingual lexical resource .",O O B O O O B I I O
"Different from the vast majority of existing approaches , we ground our embeddings on a sense inventory made available from the BabelNet semantic network .",O O O O O O O O O O O O B O O B I O O O O B I I O
"In this setting , multilingual access is governed by the mapping of terms onto their underlying sense descriptions , such that all vectors co - exist in the same semantic space .",O O O O B I O O O O B I I O O B I I O O O O B O O O O O O B I O
"As a result , for each term we have thus the “ blended ” terminological vector along with those describing all senses associated to that term .",O O O O O O O O O O O O O O B I O O O O O O O O O O O
"LESSLEX has been tested on three tasks relevant to lexical semantics : conceptual similarity , contextual similarity , and semantic text similarity .",B O O O O O O O O B I O B I O B I O O B I I O
"We experimented over the principal data sets for such tasks in their multilingual and crosslingual variants , improving on or closely approaching state - of - the - art results .",O O O O O B I O O O O O B O B O O O O O O O O O O O O O O O O
We conclude by arguing that LESSLEX vectors may be relevant for practical applications and for research on conceptual and lexical access and competence .,O O O O O B I O O O O O O O O O O O O B I O O O
"In this article , we explore the potential of using sentence - level discourse structure for machine translation evaluation .",O O O O O O O O O O B I I I I O B I I O
"We first design discourse - aware similarity measures , which use all - subtree kernels to compare discourse parse trees in accordance with the Rhetorical Structure Theory ( RST ) .",O O O B I I B I O O O B I I I O O B I I O O O O B I I O I O O
"Then , we show that a simple linear combination with these measures can help improve various existing machine translation evaluation metrics regarding correlation with human judgments both at the segment level and at the system level .",O O O O O O O B I O O O O O O O O B I I I O B I I I O O O B I O O O B I O
"This suggests that discourse information is complementary to the information used by many of the existing evaluation metrics , and thus it could be taken into account when developing richer evaluation metrics , such as the WMT-14 winning combined metric DiscoTKparty .",O O O b I O O O O O O O O O O O B I O O O O O O O O O O O O B I O O O O B O O B B O
We also provide a detailed analysis of the relevance of various discourse elements and relations from the RST parse trees for machine translation evaluation .,O O O O O O O O O O O B I O O O O B I I O B I I O
"In particular , we show that ( i ) all aspects of the RST tree are relevant , ( ii ) nuclearity is more useful than relation type , and ( iii ) the similarity of the translation RST tree to the reference RST tree is positively correlated with translation quality .",O O O O O O O O O O O O O B I O O O O O O B O O O O B I O O O O O O B O O B B I O O O B I O B I O B I O
"We introduce a generative probabilistic model , the noisy channel model , for unsupervised word sense disambiguation .",O O O B I I O O B I I O O B I I I O
"In our model , each context C is modeled as a distinct channel through which the speaker intends to transmit a particular meaning S using a possibly ambiguous word W. To reconstruct the intended meaning the hearer uses the distribution of possible meanings in the given context P(S|C ) and possible words that can express each meaning P(W|S ) .",O O O O O O O O O O O O O O O O O O O O O O O O O O O B I O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O
We assume P(W|S ) is independent of the context and estimate it using WordNet sense frequencies .,O O O O O O O O O O O O O B I I O
The main problem of unsupervised WSD is estimating context - dependent P(S|C ) without access to any sense - tagged text .,O O O O B I O O B I I O O O O O O B I I I O
We show one way to solve this problem using a statistical language model based on large amounts of untagged text .,O O O O O O O O O O B I I O O O O O B I O
Our model uses coarse - grained semantic classes for S internally and we explore the effect of using different levels of granularity on WSD performance .,O O O B I I I I O O O O O O O O O O O O O B O B I O
"The system outputs fine - grained senses for evaluation , and its performance on noun disambiguation is better than most previously reported unsupervised systems and close to the best supervised systems .",O O O B I I I O O O O O O O B I O O O O O O B I O O O O O B I O
"Weighted finite automata ( WFAs ) are often used to represent probabilistic models , such as n - gram language models , because among other things , they are efficient for recognition tasks in time and space .",B I I O B O O O O O O B I O O O B I I B I O O O O O O O O O O B I O O O O O
"The probabilistic source to be represented as a WFA , however , may come in many forms .",O B I O O O O O B O O O O O O O O O
"Given a generic probabilistic model over sequences , we propose an algorithm to approximate it as a WFA such that the Kullback - Leibler divergence between the source model and the WFA target model is minimized .",O O O B I O O O O O O B O O O O O B O O O B I I I O O B I O O B I I O O O
"The proposed algorithm involves a counting step and a difference of convex optimization step , both of which can be performed efficiently .",O O B O O O O O O O O B I I O O O O O O O O O
"We demonstrate the usefulness of our approach on various tasks , including distilling n - gram models from neural models , building compact language models , and building open - vocabulary character models .",O O O O O O O O O O O O O B I I I O B I O O O B I O O O B I I I I O
The algorithms used for these experiments are available in an open - source software library .,O B O O O O O O O O B I I I I O
We present an approach to the automatic creation of extractive summaries of literary short stories .,O O O O O O B I O B I O O O O O
The summaries are produced with a specific objective in mind : to help a reader decide whether she would be interested in reading the complete story .,O O O O O O O O O O O O O O O O O O O O O O O O O O O
"To this end , the summaries give the user relevant information about the setting of the story without revealing its plot .",O O O O O O O O O O O O O O O O O O O O O O
"The system relies on assorted surface indicators about clauses in the short story , the most important of which are those related to the aspectual type of a clause and to the main entities in a story .",O O O O O B I O B O O O O O O O O O O O O O O O B I O O B O O O O B O O O O
Fifteen judges evaluated the summaries on a number of extrinsic and intrinsic measures .,O O O O O O O O O B I I I O
Neural machine translation ( NMT ) has shown great success as a new alternative to the traditional Statistical Machine Translation model in multiple languages .,B I I I I I O O O O O O O O O O O B I I O O O O O
Early NMT models are based on sequence - to - sequence learning that encodes a sequence of source words into a vector space and generates another sequence of target words from the vector .,O B O O O O B I I I I I O B O O O O O O O B I O O O O O O O O O B O
"In those NMT models , sentences are simply treated as sequences of words without any internal structure .",O O B O O O O O O O O O O O O O O O
"In this article , we focus on the role of the syntactic structure of source sentences and propose a novel end - to - end syntactic NMT model , which we call a tree - to - sequence NMT model , extending a sequence - to - sequence model with the source - side phrase structure .",O O O O O O O O O O O B I O O O O O O O B I I I I I I I O O O O O B I I I I I I O O O B I I I I I O O B I I B I O
Our proposed model has an attention mechanism that enables the decoder to generate a translated word while softly aligning it with phrases as well as words of the source sentence .,O O O O O B I O O O B O B O O O O O O O O O O O O O O O O O O
We have empirically compared the proposed model with sequence - to - sequence models in various settings on Chinese - to - Japanese and English - to - Japanese translation tasks .,O O O O O O O O B I I I I I O O O O O O O O O O O O O O O B I O
"Our experimental results suggest that the use of syntactic structure can be beneficial when the training data set is small , but is not as effective as using a bi - directional encoder .",O O O O O O O O B I O O O O O B I O O O O O O O O O O O O B I I I O
"As the size of training data set increases , the benefits of using a syntactic tree tends to diminish .",O O O O B I I O O O O O O O B I O O O O
"Word sense disambiguation ( WSD ) is an old and important task in computational linguistics that still remains challenging , to machines as well as to human annotators .",B I I O B O O O O O O O O B I O O O O O O O O O O O O B O
Recently there have been several proposals for representing word meaning in context that diverge from the traditional use of a single best sense for each occurrence .,O O O O O O O O O O O B O O O O O O O O O O O O O O O
"They represent word meaning in context through multiple paraphrases , as points in vector space , or as distributions over latent senses .",O O O O O B O O O O O O O B I O O O B O O O O
New methods of evaluating and comparing these different representations are needed .,O O O O O O O O O O O O
In this paper we propose two novel annotation schemes that characterize word meaning in context in a graded fashion .,O O O O O O O B I O O O O O B O O O O O
"In WSsim annotation , the applicability of each dictionary sense is rated on an ordinal scale .",O B I O O O O O O O O O O O B I O
"Usim annotation directly rates the similarity of pairs of usages of the same lemma , again on a scale .",B I O O O O O O O O O O O B O O O O O O
"We find that the novel annotation schemes show good interannotator agreement , as well as a strong correlation with traditional single - sense annotation and with annotation of multiple lexical paraphrases .",O O O O O O O O O B I O O O O O B I O O O O O B O O B O O B I O
"Annotators make use of the whole ordinal scale , and give fine - grained judgments that “ mix and match ” senses for each individual usage .",B O O O O O B I O O O B I I I O O O O O O O O O O O O
"We also find that the Usim ratings obey the triangle inequality , justifying models that treat usage similarity as metric .",O O O O O B I O O O O O O O O O O O O B O
There has recently been much work on grouping senses into coarse - grained groups .,O O O O O O O O O O B I I I O
We demonstrate that graded WSsim and Usim ratings can be used to analyze existing coarse - grained sense groupings to identify sense groups that may not match intuitions of untrained native speakers .,O O O B I O B I O O O O O O B I I I O O O O O O O O O O O O O O O
"In the course of the comparison , we also show that the WSsim ratings are not subsumed by any static sense grouping .",O O O O O O O O O O O O B I O O O O O B I I O
The Levenshtein distance is a simple distance metric derived from the number of edit operations needed to transform one string into another .,O B I O O O B I O O O O O B I O O O O B O O O
This metric has received recent attention as a means of automatically classifying languages into genealogical subgroups .,O O O O O O O O O O O O O O B I O
In this article I test the performance of the Levenshtein distance for classifying languages by subsampling three language subsets from a large database of Austronesian languages .,O O O O O O O O O B I O B I O B O O O O O O O O O O O
Comparing the classification proposed by the Levenshtein distance to that of the comparative method shows that the Levenshtein classification is correct only 40 % of time .,O O O O O O B I O O O O B I O O O B I O O O O O O O O
"Standardizing the orthography increases the performance , but only to a maximum of 65 % accuracy within language subgroups .",O O B O O O O O O O O O O O O O O O O O
"The accuracy of the Levenshtein classification decreases rapidly with phylogenetic distance , failing to discriminate homology and chance similarity across distantly related languages .",O O O O B I O O O B I O O O O B O O O O O O O O
This poor performance suggests the need for more linguistically nuanced methods for automated language classification tasks .,O O O O O O O O O O O O B I I O O
